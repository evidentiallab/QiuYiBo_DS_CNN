{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my3bB6Xl6qaH"
      },
      "source": [
        "This is a demo based on the FitNet-4 classifier for probablistic and evidential classification, which can be run on the google colab.\n",
        "\n",
        "Please check two points before running the demo:\n",
        "1. Use GPU or TPU in Google colab to improve the running speed as:\n",
        "edit >> Notebook setting >> Hardware accelerator >> Select GPU or TPU >> Save.\n",
        "\n",
        "2. Check the versions of the used libs, especially TensorFlow. The required versions of these libs can be found in the readme file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thiYhNDH66eP"
      },
      "source": [
        "The first step is to import the pre-requisite libs as below.\n",
        "The required versions of these libs can be found in the readme file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6Nwj3IC5nst",
        "outputId": "701076ee-19b8-43bc-d2e7-17f10a7d1ea9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "print(tf.__version__)\n",
        "print(\"python版本:%s\"% sys.version)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "sys.path.append('/content/gdrive/My Drive/cifar10_evidential/libs')\n",
        "import ds_layer #Dempster-Shafer layer\n",
        "import utility_layer_train #Utility layer for training\n",
        "import utility_layer_test #Utility layer for training\n",
        "import AU_imprecision #Metric average utility for set-valued classification\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvSPrEFn7k1Z"
      },
      "source": [
        "Let's get and pre-process the CIFAR-10 database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOw9XlJW6olk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0b8b00-830c-4ff7-99b6-0c2c2bfa8e36"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train=x_train.astype(\"float32\") / 255.0\n",
        "x_test=x_test.astype(\"float32\") / 255.0\n",
        "y_train_label = y_train\n",
        "y_test_label = y_test\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mT4kY4K7vCG"
      },
      "source": [
        "Let's build a probablistic FitNet-4 classifier.\n",
        "\n",
        "In the demo, we use the fixed learning rate and do not introduce data augmentation as well as some other technologies because the demo just try to show the difference between evidential and proabilistic FitNet-4 classifiers. If users wish to achieve the resutls reported in the papers ('Fitnets: Hints for thin deep nets' and 'All you need is a good init'), please refer their hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7zhRG6R7433",
        "outputId": "f0f265e4-35e5-4a7f-a06d-c14e23cdcf8f"
      },
      "source": [
        "IMG_WIDTH = 32\n",
        "IMG_HEIGHT = 32\n",
        "IMG_CHANNELS = 3\n",
        "num_class=10\n",
        "\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "c1_1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "c1_2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_1)\n",
        "c1_3 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_2)\n",
        "c1_4 = tf.keras.layers.Conv2D(48, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_3)\n",
        "c1_5 = tf.keras.layers.Conv2D(48, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_4)\n",
        "bt1 = tf.keras.layers.BatchNormalization()(c1_5)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(bt1)\n",
        "dr1 = tf.keras.layers.Dropout(0.5)(p1)\n",
        "\n",
        "\n",
        "c2_1 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(dr1)\n",
        "c2_2 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_1)\n",
        "c2_3 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_2)\n",
        "c2_4 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_3)\n",
        "c2_5 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_4)\n",
        "bt2 = tf.keras.layers.BatchNormalization()(c2_5)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(bt2)\n",
        "dr2 = tf.keras.layers.Dropout(0.5)(p2)\n",
        "\n",
        "c3_1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(dr2)\n",
        "c3_2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_1)\n",
        "c3_3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_2)\n",
        "c3_4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_3)\n",
        "c3_5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_4)\n",
        "bt3 = tf.keras.layers.BatchNormalization()(c3_5)\n",
        "p3 = tf.keras.layers.MaxPooling2D((8, 8))(bt3)\n",
        "dr3 = tf.keras.layers.Dropout(0.5)(p3)\n",
        "\n",
        "flatten1=tf.keras.layers.Flatten()(dr3)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(num_class, activation='softmax')(flatten1)\n",
        "\n",
        "model_p = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model_p.compile(optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004), #lr=0.005\n",
        "              loss='CategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_p.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 48)        13872     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 48)        20784     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 48)        192       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 48)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 80)        34640     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 16, 16, 80)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 80)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 80)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         92288     \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,004,346\n",
            "Trainable params: 1,003,834\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5vAvprB-Mg3"
      },
      "source": [
        "Let's train the probabilistic FitNet classifier.\n",
        "\n",
        "In the demo, the weights will be saved if the validation average utility is  improved after one epoch.\n",
        "\n",
        "As mentioned in our paper, when only considering the precise classification during training, the average utility equals to the average accuracy.\n",
        "\n",
        "Users is suggested to stop training when the training accuracy is close to 1. The authors also provide the weights of the model in the model zoo, users can directly load it in the next cell, instead of strating with pre-training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBaxcsf09pIX"
      },
      "source": [
        "filepath = ''#please define our own filepath to save the weights of the probabilistic FitNet-4 classifier\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath, monitor='val_accuracy', verbose=1,\n",
        "    save_best_only=True, save_weights_only=True,\n",
        "    save_frequency=1)\n",
        "\n",
        "model_p.fit(x_train, y_train, batch_size=25, epochs=200, verbose=1, callbacks=[checkpoint_callback], validation_data=(x_test, y_test), shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UMtyaI9_bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4fb5e6-f4d2-4541-d8e9-97c2caa18318"
      },
      "source": [
        "model_p.load_weights('/content/gdrive/My Drive/cifar10_evidential/weights_zoo/cnn_checkpoint_final')# replace the path with your own\n",
        "model_p.evaluate(x_train, y_train, batch_size=25, verbose=1)\n",
        "model_p.evaluate(x_test, y_test, batch_size=25, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 10s 3ms/step - loss: 0.0021 - accuracy: 0.9993\n",
            "400/400 [==============================] - 1s 3ms/step - loss: 0.8291 - accuracy: 0.8708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8290520310401917, 0.8708000183105469]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmpYviSsc3-Q"
      },
      "source": [
        "Let's build an evidential FitNet-4 classifier.\n",
        "\n",
        "Compared to the probabilistic one, the evidential classifier has the extra hyper-parameters: the number of prototypes and pessimism index \\nu (if use generalized Hurwicz decision criterion). The classifier has 200 prototypes and uses the generalized Hurwicz decision criterion with \\nu=0.9. The two hyper-parameters can be tuned using a validation set or by cross-validation.\n",
        "\n",
        "We also provide the utility layer based on Pignistic criterion, please find the details in utility_layer_train.py.\n",
        "\n",
        "In the demo, we use the fixed learning rate and do not introduce data augmentation as well as some other technologies because the demo just try to show the difference between evidential and proabilistic FitNet-4 classifiers. If users wish to achieve the resutls reported in the paper ('Fitnets: Hints for thin deep nets' and 'All you need is a good init'), please refer their hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bErpieRJFhKI",
        "outputId": "7e28b2ac-ad6b-4ce1-ad2c-435b231b8185"
      },
      "source": [
        "IMG_WIDTH = 32\n",
        "IMG_HEIGHT = 32\n",
        "IMG_CHANNELS = 3\n",
        "inputs_pixels = IMG_WIDTH * IMG_HEIGHT\n",
        "prototypes=200\n",
        "num_class=10\n",
        "\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "#convolution stages\n",
        "c1_1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "c1_2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_1)\n",
        "c1_3 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_2)\n",
        "c1_4 = tf.keras.layers.Conv2D(48, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_3)\n",
        "c1_5 = tf.keras.layers.Conv2D(48, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_4)\n",
        "bt1 = tf.keras.layers.BatchNormalization()(c1_5)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(bt1)\n",
        "dr1 = tf.keras.layers.Dropout(0.5)(p1)\n",
        "\n",
        "\n",
        "c2_1 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(dr1)\n",
        "c2_2 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_1)\n",
        "c2_3 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_2)\n",
        "c2_4 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_3)\n",
        "c2_5 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_4)\n",
        "bt2 = tf.keras.layers.BatchNormalization()(c2_5)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(bt2)\n",
        "dr2 = tf.keras.layers.Dropout(0.5)(p2)\n",
        "\n",
        "c3_1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(dr2)\n",
        "c3_2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_1)\n",
        "c3_3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_2)\n",
        "c3_4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_3)\n",
        "c3_5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_4)\n",
        "bt3 = tf.keras.layers.BatchNormalization()(c3_5)\n",
        "p3 = tf.keras.layers.MaxPooling2D((8, 8))(bt3)\n",
        "dr3 = tf.keras.layers.Dropout(0.5)(p3)\n",
        "flatten1=tf.keras.layers.Flatten()(dr3)\n",
        "\n",
        "#DS layer\n",
        "ED = ds_layer.DS1(prototypes,128)(flatten1)\n",
        "ED_ac = ds_layer.DS1_activate(prototypes)(ED)\n",
        "mass_prototypes = ds_layer.DS2(prototypes, num_class)(ED_ac)\n",
        "mass_prototypes_omega = ds_layer.DS2_omega(prototypes, num_class)(mass_prototypes)\n",
        "mass_Dempster = ds_layer.DS3_Dempster(prototypes, num_class)(mass_prototypes_omega)\n",
        "mass_Dempster_normalize = ds_layer.DS3_normalize()(mass_Dempster)\n",
        "\n",
        "#Utility layer for training\n",
        "outputs = utility_layer_train.DM(0.9, num_class)(mass_Dempster_normalize)\n",
        "\n",
        "\n",
        "model_e = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model_e.compile(optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004), \n",
        "              loss='CategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_e.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_90 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 32, 32, 48)        13872     \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 32, 32, 48)        20784     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 32, 32, 48)        192       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 16, 16, 48)        0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 16, 16, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 16, 16, 80)        34640     \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 16, 16, 80)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 8, 8, 80)          0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 8, 8, 80)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 8, 8, 128)         92288     \n",
            "_________________________________________________________________\n",
            "conv2d_101 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_103 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "d_s1_14 (DS1)                (None, 200)               25600     \n",
            "_________________________________________________________________\n",
            "d_s1_activate_14 (DS1_activa (None, 200)               400       \n",
            "_________________________________________________________________\n",
            "d_s2_14 (DS2)                (None, 200, 10)           2000      \n",
            "_________________________________________________________________\n",
            "d_s2_omega_14 (DS2_omega)    (None, 200, 11)           0         \n",
            "_________________________________________________________________\n",
            "d_s3__dempster_14 (DS3_Demps (None, 11)                0         \n",
            "_________________________________________________________________\n",
            "d_s3_normalize_14 (DS3_norma (None, 11)                0         \n",
            "_________________________________________________________________\n",
            "dm_14 (DM)                   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,031,056\n",
            "Trainable params: 1,030,544\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klyUQT3zRddd"
      },
      "source": [
        "The training beginning with random  initialized parameters is time consuming and slow. The authors suggests users directly use the weights from probabilistic CNN classifier and then fine-tune the paramters in DS layer and golable weights in the evidential CNN classifier as shown in the cell. If a user want to just use the well-trained classifier, please see the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSl0dIMCJ8eW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0146a088-b13b-40b9-9cb4-677f020680f4"
      },
      "source": [
        "#get the features using the probabilistic classifier\n",
        "model_e.load_weights('') #please give our own filepath to save the weights of the probabilistic FitNet-4 classifier\n",
        "feature = tf.keras.Model(inputs=[inputs], outputs=[flatten1])\n",
        "x_train_feature = feature.predict(x_train)\n",
        "x_test_feature = feature.predict(x_test)\n",
        "\n",
        "#Use the features to train DS layer\n",
        "inputs = tf.keras.layers.Input(128)\n",
        "ED = ds_layer.DS1(prototypes,128)(inputs)\n",
        "ED_ac = ds_layer.DS1_activate(prototypes)(ED)\n",
        "mass_prototypes = ds_layer.DS2(prototypes, num_class)(ED_ac)\n",
        "mass_prototypes_omega = ds_layer.DS2_omega(prototypes, num_class)(mass_prototypes)\n",
        "mass_Dempster = ds_layer.DS3_Dempster(prototypes, num_class)(mass_prototypes_omega)\n",
        "mass_Dempster_normalize = ds_layer.DS3_normalize()(mass_Dempster)\n",
        "outputs = utility_layer_train.DM(0.9, num_class)(mass_Dempster_normalize)\n",
        "model_mid = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model_mid.compile(optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004), #0.001\n",
        "              loss='CategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_mid.fit(x_train_feature, y_train, batch_size=25,  epochs=2, verbose=1, validation_data=(x_test_feature, y_test), shuffle=True)\n",
        "\n",
        "#give the trained paramters to the evidential model\n",
        "model_e.load_weights('')#please give our own filepath to save the weights of the probabilistic FitNet-4 classifier\n",
        "DSLAYER_DS1_W = tf.reshape(model_mid.layers[1].get_weights()[0], [1, 200, 128])\n",
        "DSLAYER_DS1_activate_W = model_mid.layers[2].get_weights()\n",
        "DSLAYER_DS2_W = model_mid.layers[3].get_weights()\n",
        "model_e.layers[26].set_weights(DSLAYER_DS1_W)\n",
        "model_e.layers[27].set_weights(DSLAYER_DS1_activate_W)\n",
        "model_e.layers[28].set_weights(DSLAYER_DS2_W)\n",
        "\n",
        "#fine-tune the golable weights in the evidential CNN classifier and evaluate the classifier\n",
        "filepath = ''#define our own path to save the weights of the evidential FitNet-4 classifier\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath, monitor='val_accuracy', verbose=1,\n",
        "    save_best_only=True, save_weights_only=True,\n",
        "    save_frequency=1)\n",
        "model_e.fit(x_train, y_train, batch_size=25,  epochs=3, verbose=1, callbacks=[checkpoint_callback], validation_data=(x_test, y_test), shuffle=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-18.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-18.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-18.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-18.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-18.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-18.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-18.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-18.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-18.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-18.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-18.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-18.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "2000/2000 [==============================] - 276s 106ms/step - loss: 1.2926 - accuracy: 0.5521 - val_loss: 0.7246 - val_accuracy: 0.8548\n",
            "Epoch 2/3\n",
            "2000/2000 [==============================] - 200s 100ms/step - loss: 0.1199 - accuracy: 0.9903 - val_loss: 0.7743 - val_accuracy: 0.8576\n",
            "Epoch 3/3\n",
            "2000/2000 [==============================] - 199s 100ms/step - loss: 0.0661 - accuracy: 0.9937 - val_loss: 0.8522 - val_accuracy: 0.8683\n",
            "Epoch 1/3\n",
            "2000/2000 [==============================] - 503s 217ms/step - loss: 0.2390 - accuracy: 0.9407 - val_loss: 0.7635 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.86490, saving model to /content/gdrive/My Drive/evidential_DL_200_checkpoint\n",
            "Epoch 2/3\n",
            "2000/2000 [==============================] - 418s 209ms/step - loss: 0.0699 - accuracy: 0.9877 - val_loss: 0.8444 - val_accuracy: 0.8648\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.86490\n",
            "Epoch 3/3\n",
            "2000/2000 [==============================] - 419s 209ms/step - loss: 0.0776 - accuracy: 0.9862 - val_loss: 0.8489 - val_accuracy: 0.8751\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.86490 to 0.87510, saving model to /content/gdrive/My Drive/evidential_DL_200_checkpoint\n",
            "2000/2000 [==============================] - 81s 40ms/step - loss: 0.0199 - accuracy: 0.9995\n",
            "400/400 [==============================] - 16s 40ms/step - loss: 0.8489 - accuracy: 0.8751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8489488363265991, 0.8751000165939331]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__27YVALGBUE"
      },
      "source": [
        "After training, the average utility of evidential classifier is slightly higer than the one of probablisitic classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGE_fgbWK6bq",
        "outputId": "aa0a6695-c29e-49db-cac9-49c993d400fd"
      },
      "source": [
        "model_e.load_weights('/content/gdrive/My Drive/cifar10_evidential/weights_zoo/evidential_DL_200_checkpoint')\n",
        "model_e.evaluate(x_train, y_train, batch_size=25, verbose=1)\n",
        "model_e.evaluate(x_test, y_test, batch_size=25, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<ds_layer.DS2 object at 0x7f0aa3c47210> and <ds_layer.DS3_normalize object at 0x7f0aa3b8d710>).\n",
            "2000/2000 [==============================] - 51s 19ms/step - loss: 0.0631 - accuracy: 0.9970\n",
            "400/400 [==============================] - 8s 19ms/step - loss: 0.6747 - accuracy: 0.8757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6746578216552734, 0.8756999969482422]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BxQv1poGQco"
      },
      "source": [
        "Let's see the set-valued classificaiton of the evidential FitNet-4 classifier. \n",
        "\n",
        "We first generate a utility matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJW0nKwrGPpG"
      },
      "source": [
        "# aim func: cross entropy\n",
        "def func(x):\n",
        "  fun=0\n",
        "  for i in range(len(x)):\n",
        "    fun += x[i] * math.log10(x[i])\n",
        "  return fun\n",
        "\n",
        "#constraint 1: the sum of weights is 1\n",
        "def cons1(x):\n",
        "  return sum(x)\n",
        "\n",
        "#constraint 2: define tolerance to imprecision\n",
        "def cons2(x):\n",
        "  tol = 0\n",
        "  for i in range(len(x)):\n",
        "    tol += (len(x) -(i+1)) * x[i] / (len(x) - 1)\n",
        "  return tol"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dghicwcvGtAy",
        "outputId": "963f90db-762d-4249-8f47-48f8a2fcbd26"
      },
      "source": [
        "#compute the weights g for ordered weighted average aggreagtion\n",
        "num_class = 10\n",
        "for j in range(2,(num_class+1)):\n",
        "  num_weights = j\n",
        "  ini_weights = np.asarray(np.random.rand(num_weights))\n",
        "\n",
        "  name='weight'+str(j)\n",
        "  locals()['weight'+str(j)]= np.zeros([5, j])\n",
        "\n",
        "  for i in range(5):\n",
        "    tol = 0.5 + i * 0.1\n",
        "\n",
        "    cons = ({'type': 'eq', 'fun' : lambda x: cons1(x)-1},\n",
        "          {'type': 'eq', 'fun' : lambda x: cons2(x)-tol},\n",
        "          {'type': 'ineq', 'fun' : lambda x: x-0.00000001}\n",
        "        )\n",
        "  \n",
        "    res = minimize(func, ini_weights, method='SLSQP', options={'disp': True}, constraints=cons)\n",
        "    locals()['weight'+str(j)][i] = res.x\n",
        "    print (res.x)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.30102999566398125\n",
            "            Iterations: 2\n",
            "            Function evaluations: 8\n",
            "            Gradient evaluations: 2\n",
            "[0.5 0.5]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.29228525323862886\n",
            "            Iterations: 2\n",
            "            Function evaluations: 8\n",
            "            Gradient evaluations: 2\n",
            "[0.6 0.4]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.2652949955741215\n",
            "            Iterations: 2\n",
            "            Function evaluations: 8\n",
            "            Gradient evaluations: 2\n",
            "[0.7 0.3]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.2173220112736488\n",
            "            Iterations: 2\n",
            "            Function evaluations: 8\n",
            "            Gradient evaluations: 2\n",
            "[0.8 0.2]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.1411817415046075\n",
            "            Iterations: 2\n",
            "            Function evaluations: 8\n",
            "            Gradient evaluations: 2\n",
            "[0.9 0.1]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.47712125462928956\n",
            "            Iterations: 4\n",
            "            Function evaluations: 20\n",
            "            Gradient evaluations: 4\n",
            "[0.33332852 0.33334295 0.33332852]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.4639930049435555\n",
            "            Iterations: 4\n",
            "            Function evaluations: 20\n",
            "            Gradient evaluations: 4\n",
            "[0.43836969 0.32326063 0.23836969]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.4233254757403061\n",
            "            Iterations: 4\n",
            "            Function evaluations: 20\n",
            "            Gradient evaluations: 4\n",
            "[0.55380438 0.29239124 0.15380438]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.35041889160183015\n",
            "            Iterations: 3\n",
            "            Function evaluations: 16\n",
            "            Gradient evaluations: 3\n",
            "[0.68208412 0.23583176 0.08208412]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.2325876953610533\n",
            "            Iterations: 6\n",
            "            Function evaluations: 32\n",
            "            Gradient evaluations: 6\n",
            "[0.82626492 0.14747015 0.02626492]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.6020598327474102\n",
            "            Iterations: 4\n",
            "            Function evaluations: 25\n",
            "            Gradient evaluations: 4\n",
            "[0.24981586 0.25035322 0.24984599 0.24998493]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.586295258518285\n",
            "            Iterations: 3\n",
            "            Function evaluations: 19\n",
            "            Gradient evaluations: 3\n",
            "[0.34748497 0.27196299 0.21361911 0.16693293]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.537318568717354\n",
            "            Iterations: 6\n",
            "            Function evaluations: 37\n",
            "            Gradient evaluations: 6\n",
            "[0.46143554 0.27549062 0.16471214 0.0983617 ]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.44888807290738697\n",
            "            Iterations: 6\n",
            "            Function evaluations: 38\n",
            "            Gradient evaluations: 6\n",
            "[0.59642939 0.2520523  0.10660723 0.04491108]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.3036738966449429\n",
            "            Iterations: 7\n",
            "            Function evaluations: 48\n",
            "            Gradient evaluations: 7\n",
            "[0.76392672 0.18222587 0.0437681  0.01007931]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.6989699767125517\n",
            "            Iterations: 8\n",
            "            Function evaluations: 58\n",
            "            Gradient evaluations: 8\n",
            "[0.1999892  0.19997542 0.19999345 0.20013006 0.19991188]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.6814447453269289\n",
            "            Iterations: 10\n",
            "            Function evaluations: 73\n",
            "            Gradient evaluations: 10\n",
            "[0.28830896 0.23543742 0.1919325  0.1565869  0.12773422]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.6268723195129932\n",
            "            Iterations: 9\n",
            "            Function evaluations: 68\n",
            "            Gradient evaluations: 9\n",
            "[0.39570241 0.25752505 0.1679776  0.10866002 0.07013492]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.5277824992952518\n",
            "            Iterations: 12\n",
            "            Function evaluations: 90\n",
            "            Gradient evaluations: 12\n",
            "[0.53099253 0.2560392  0.12397337 0.05996552 0.02902937]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.3628892895440308\n",
            "            Iterations: 12\n",
            "            Function evaluations: 92\n",
            "            Gradient evaluations: 12\n",
            "[0.71059787 0.20654014 0.06023644 0.01751522 0.00511033]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.7781509764915153\n",
            "            Iterations: 10\n",
            "            Function evaluations: 81\n",
            "            Gradient evaluations: 10\n",
            "[0.16674518 0.16652145 0.16650943 0.16704743 0.16656519 0.16661134]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.7593665910806107\n",
            "            Iterations: 12\n",
            "            Function evaluations: 101\n",
            "            Gradient evaluations: 12\n",
            "[0.24673141 0.20724617 0.17406525 0.14624416 0.12267417 0.10303883]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.700768911541362\n",
            "            Iterations: 13\n",
            "            Function evaluations: 110\n",
            "            Gradient evaluations: 13\n",
            "[0.34764618 0.23931288 0.16574207 0.11434046 0.07861045 0.05434796]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.5938824144155143\n",
            "            Iterations: 17\n",
            "            Function evaluations: 146\n",
            "            Gradient evaluations: 17\n",
            "[0.47796496 0.25496931 0.13572235 0.07233855 0.0384538  0.02055102]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.41403443636725906\n",
            "            Iterations: 14\n",
            "            Function evaluations: 125\n",
            "            Gradient evaluations: 14\n",
            "[0.66394252 0.2234806  0.07563332 0.02540225 0.00866056 0.00288075]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.8450980382808109\n",
            "            Iterations: 5\n",
            "            Function evaluations: 49\n",
            "            Gradient evaluations: 5\n",
            "[0.14287238 0.14285942 0.1428282  0.14285936 0.14285659 0.14286454\n",
            " 0.14285951]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.8253677972632905\n",
            "            Iterations: 5\n",
            "            Function evaluations: 50\n",
            "            Gradient evaluations: 5\n",
            "[0.2157081  0.18524619 0.1589536  0.1363884  0.117033   0.10047492\n",
            " 0.0861958 ]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.7637322451763144\n",
            "            Iterations: 9\n",
            "            Function evaluations: 85\n",
            "            Gradient evaluations: 9\n",
            "[0.30941171 0.22391744 0.16139271 0.11651992 0.08408777 0.06063637\n",
            " 0.04403408]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.6508873318066395\n",
            "            Iterations: 12\n",
            "            Function evaluations: 116\n",
            "            Gradient evaluations: 12\n",
            "[0.43510361 0.24964275 0.14325907 0.08223513 0.04718318 0.02705657\n",
            " 0.01551969]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.4592335321771322\n",
            "            Iterations: 12\n",
            "            Function evaluations: 122\n",
            "            Gradient evaluations: 12\n",
            "[0.6226773  0.23527824 0.08894732 0.03374936 0.01287973 0.00474822\n",
            " 0.00171984]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.9030899572963668\n",
            "            Iterations: 7\n",
            "            Function evaluations: 73\n",
            "            Gradient evaluations: 7\n",
            "[0.12494372 0.12503902 0.12506389 0.1249795  0.12494823 0.1250099\n",
            " 0.12505787 0.12495786]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.8826236474663947\n",
            "            Iterations: 8\n",
            "            Function evaluations: 88\n",
            "            Gradient evaluations: 8\n",
            "[0.19172358 0.16740415 0.14608733 0.12751451 0.11131036 0.09714416\n",
            " 0.08479598 0.07401994]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.8186139708256944\n",
            "            Iterations: 14\n",
            "            Function evaluations: 147\n",
            "            Gradient evaluations: 14\n",
            "[0.27920574 0.20891576 0.1563344  0.11692187 0.08763721 0.06541039\n",
            " 0.04897338 0.03660125]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.7010596281575375\n",
            "            Iterations: 14\n",
            "            Function evaluations: 153\n",
            "            Gradient evaluations: 14\n",
            "[0.39889363 0.24282403 0.14778498 0.08996337 0.05507359 0.0333288\n",
            " 0.02014372 0.01198789]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.4998271033571912\n",
            "            Iterations: 17\n",
            "            Function evaluations: 192\n",
            "            Gradient evaluations: 17\n",
            "[0.5862306  0.24295361 0.10063684 0.04163837 0.01724485 0.0071162\n",
            " 0.00295951 0.00122002]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.9542425062600922\n",
            "            Iterations: 15\n",
            "            Function evaluations: 174\n",
            "            Gradient evaluations: 15\n",
            "[0.111106   0.11110592 0.11110851 0.11113229 0.11112507 0.11108336\n",
            " 0.1111215  0.11110459 0.11111274]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.9331865845453656\n",
            "            Iterations: 22\n",
            "            Function evaluations: 258\n",
            "            Gradient evaluations: 22\n",
            "[0.17253363 0.15279982 0.13504931 0.1195178  0.10559448 0.09378787\n",
            " 0.08268248 0.07314089 0.06489373]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.8672674220348616\n",
            "            Iterations: 20\n",
            "            Function evaluations: 239\n",
            "            Gradient evaluations: 20\n",
            "[0.25394731 0.19581534 0.1509679  0.11671785 0.08882672 0.0687772\n",
            " 0.05315555 0.04036787 0.03142426]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.7459042820789246\n",
            "            Iterations: 23\n",
            "            Function evaluations: 275\n",
            "            Gradient evaluations: 23\n",
            "[0.36879498 0.23509458 0.14994443 0.09558861 0.06103861 0.03898821\n",
            " 0.02474604 0.01575731 0.01004722]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.5367165674405341\n",
            "            Iterations: 19\n",
            "            Function evaluations: 234\n",
            "            Gradient evaluations: 19\n",
            "[0.55364786 0.24738009 0.11057215 0.04966544 0.02190603 0.0097486\n",
            " 0.00427325 0.00197997 0.00082662]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.9999999696338958\n",
            "            Iterations: 8\n",
            "            Function evaluations: 100\n",
            "            Gradient evaluations: 8\n",
            "[0.09999242 0.09994207 0.10000017 0.10005851 0.10003778 0.09999989\n",
            " 0.1000199  0.09994729 0.10003665 0.09996532]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.9784618927883464\n",
            "            Iterations: 16\n",
            "            Function evaluations: 203\n",
            "            Gradient evaluations: 16\n",
            "[0.15690159 0.14036854 0.12557958 0.11234098 0.10050772 0.08991864\n",
            " 0.0804368  0.07196371 0.06438344 0.057599  ]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.9109709353938173\n",
            "            Iterations: 14\n",
            "            Function evaluations: 181\n",
            "            Gradient evaluations: 14\n",
            "[0.23331572 0.18404043 0.14489536 0.11438463 0.0900491  0.07109322\n",
            " 0.05683772 0.04415369 0.03382081 0.02740931]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.7864591433860704\n",
            "            Iterations: 16\n",
            "            Function evaluations: 208\n",
            "            Gradient evaluations: 16\n",
            "[0.34251662 0.2271863  0.1507248  0.09989811 0.06624384 0.04393717\n",
            " 0.02906298 0.01927865 0.01268376 0.00846778]\n",
            "Optimization terminated successfully.    (Exit mode 0)\n",
            "            Current function value: -0.5705608872360399\n",
            "            Iterations: 16\n",
            "            Function evaluations: 221\n",
            "            Gradient evaluations: 16\n",
            "[0.52476199 0.24964728 0.11866353 0.05653501 0.02688462 0.0126736\n",
            " 0.00601742 0.00276901 0.00140141 0.00064614]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7kU8KGfG0PJ"
      },
      "source": [
        "#function for power set\n",
        "def PowerSetsBinary(items):  \n",
        "    #generate all combination of N items  \n",
        "    N = len(items)  \n",
        "    #enumerate the 2**N possible combinations  \n",
        "    set_all=[]\n",
        "    for i in range(2**N):\n",
        "        combo = []  \n",
        "        for j in range(N):  \n",
        "            if(i >> j ) % 2 == 1:  \n",
        "                combo.append(items[j]) \n",
        "        set_all.append(combo)\n",
        "    return set_all"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RwdGN2YG18H",
        "outputId": "fe215cd5-e210-4fbe-cd43-1fc31515e6f2"
      },
      "source": [
        "class_set=list(range(num_class))\n",
        "act_set= PowerSetsBinary(class_set)\n",
        "act_set.remove(act_set[0])#emptyset is not needed\n",
        "act_set=sorted(act_set)\n",
        "print(act_set)\n",
        "print(len(act_set))\n",
        "#label_dict = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer',\n",
        "#              5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0], [0, 1], [0, 1, 2], [0, 1, 2, 3], [0, 1, 2, 3, 4], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6, 7], [0, 1, 2, 3, 4, 5, 6, 7, 8], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 9], [0, 1, 2, 3, 4, 5, 6, 8], [0, 1, 2, 3, 4, 5, 6, 8, 9], [0, 1, 2, 3, 4, 5, 6, 9], [0, 1, 2, 3, 4, 5, 7], [0, 1, 2, 3, 4, 5, 7, 8], [0, 1, 2, 3, 4, 5, 7, 8, 9], [0, 1, 2, 3, 4, 5, 7, 9], [0, 1, 2, 3, 4, 5, 8], [0, 1, 2, 3, 4, 5, 8, 9], [0, 1, 2, 3, 4, 5, 9], [0, 1, 2, 3, 4, 6], [0, 1, 2, 3, 4, 6, 7], [0, 1, 2, 3, 4, 6, 7, 8], [0, 1, 2, 3, 4, 6, 7, 8, 9], [0, 1, 2, 3, 4, 6, 7, 9], [0, 1, 2, 3, 4, 6, 8], [0, 1, 2, 3, 4, 6, 8, 9], [0, 1, 2, 3, 4, 6, 9], [0, 1, 2, 3, 4, 7], [0, 1, 2, 3, 4, 7, 8], [0, 1, 2, 3, 4, 7, 8, 9], [0, 1, 2, 3, 4, 7, 9], [0, 1, 2, 3, 4, 8], [0, 1, 2, 3, 4, 8, 9], [0, 1, 2, 3, 4, 9], [0, 1, 2, 3, 5], [0, 1, 2, 3, 5, 6], [0, 1, 2, 3, 5, 6, 7], [0, 1, 2, 3, 5, 6, 7, 8], [0, 1, 2, 3, 5, 6, 7, 8, 9], [0, 1, 2, 3, 5, 6, 7, 9], [0, 1, 2, 3, 5, 6, 8], [0, 1, 2, 3, 5, 6, 8, 9], [0, 1, 2, 3, 5, 6, 9], [0, 1, 2, 3, 5, 7], [0, 1, 2, 3, 5, 7, 8], [0, 1, 2, 3, 5, 7, 8, 9], [0, 1, 2, 3, 5, 7, 9], [0, 1, 2, 3, 5, 8], [0, 1, 2, 3, 5, 8, 9], [0, 1, 2, 3, 5, 9], [0, 1, 2, 3, 6], [0, 1, 2, 3, 6, 7], [0, 1, 2, 3, 6, 7, 8], [0, 1, 2, 3, 6, 7, 8, 9], [0, 1, 2, 3, 6, 7, 9], [0, 1, 2, 3, 6, 8], [0, 1, 2, 3, 6, 8, 9], [0, 1, 2, 3, 6, 9], [0, 1, 2, 3, 7], [0, 1, 2, 3, 7, 8], [0, 1, 2, 3, 7, 8, 9], [0, 1, 2, 3, 7, 9], [0, 1, 2, 3, 8], [0, 1, 2, 3, 8, 9], [0, 1, 2, 3, 9], [0, 1, 2, 4], [0, 1, 2, 4, 5], [0, 1, 2, 4, 5, 6], [0, 1, 2, 4, 5, 6, 7], [0, 1, 2, 4, 5, 6, 7, 8], [0, 1, 2, 4, 5, 6, 7, 8, 9], [0, 1, 2, 4, 5, 6, 7, 9], [0, 1, 2, 4, 5, 6, 8], [0, 1, 2, 4, 5, 6, 8, 9], [0, 1, 2, 4, 5, 6, 9], [0, 1, 2, 4, 5, 7], [0, 1, 2, 4, 5, 7, 8], [0, 1, 2, 4, 5, 7, 8, 9], [0, 1, 2, 4, 5, 7, 9], [0, 1, 2, 4, 5, 8], [0, 1, 2, 4, 5, 8, 9], [0, 1, 2, 4, 5, 9], [0, 1, 2, 4, 6], [0, 1, 2, 4, 6, 7], [0, 1, 2, 4, 6, 7, 8], [0, 1, 2, 4, 6, 7, 8, 9], [0, 1, 2, 4, 6, 7, 9], [0, 1, 2, 4, 6, 8], [0, 1, 2, 4, 6, 8, 9], [0, 1, 2, 4, 6, 9], [0, 1, 2, 4, 7], [0, 1, 2, 4, 7, 8], [0, 1, 2, 4, 7, 8, 9], [0, 1, 2, 4, 7, 9], [0, 1, 2, 4, 8], [0, 1, 2, 4, 8, 9], [0, 1, 2, 4, 9], [0, 1, 2, 5], [0, 1, 2, 5, 6], [0, 1, 2, 5, 6, 7], [0, 1, 2, 5, 6, 7, 8], [0, 1, 2, 5, 6, 7, 8, 9], [0, 1, 2, 5, 6, 7, 9], [0, 1, 2, 5, 6, 8], [0, 1, 2, 5, 6, 8, 9], [0, 1, 2, 5, 6, 9], [0, 1, 2, 5, 7], [0, 1, 2, 5, 7, 8], [0, 1, 2, 5, 7, 8, 9], [0, 1, 2, 5, 7, 9], [0, 1, 2, 5, 8], [0, 1, 2, 5, 8, 9], [0, 1, 2, 5, 9], [0, 1, 2, 6], [0, 1, 2, 6, 7], [0, 1, 2, 6, 7, 8], [0, 1, 2, 6, 7, 8, 9], [0, 1, 2, 6, 7, 9], [0, 1, 2, 6, 8], [0, 1, 2, 6, 8, 9], [0, 1, 2, 6, 9], [0, 1, 2, 7], [0, 1, 2, 7, 8], [0, 1, 2, 7, 8, 9], [0, 1, 2, 7, 9], [0, 1, 2, 8], [0, 1, 2, 8, 9], [0, 1, 2, 9], [0, 1, 3], [0, 1, 3, 4], [0, 1, 3, 4, 5], [0, 1, 3, 4, 5, 6], [0, 1, 3, 4, 5, 6, 7], [0, 1, 3, 4, 5, 6, 7, 8], [0, 1, 3, 4, 5, 6, 7, 8, 9], [0, 1, 3, 4, 5, 6, 7, 9], [0, 1, 3, 4, 5, 6, 8], [0, 1, 3, 4, 5, 6, 8, 9], [0, 1, 3, 4, 5, 6, 9], [0, 1, 3, 4, 5, 7], [0, 1, 3, 4, 5, 7, 8], [0, 1, 3, 4, 5, 7, 8, 9], [0, 1, 3, 4, 5, 7, 9], [0, 1, 3, 4, 5, 8], [0, 1, 3, 4, 5, 8, 9], [0, 1, 3, 4, 5, 9], [0, 1, 3, 4, 6], [0, 1, 3, 4, 6, 7], [0, 1, 3, 4, 6, 7, 8], [0, 1, 3, 4, 6, 7, 8, 9], [0, 1, 3, 4, 6, 7, 9], [0, 1, 3, 4, 6, 8], [0, 1, 3, 4, 6, 8, 9], [0, 1, 3, 4, 6, 9], [0, 1, 3, 4, 7], [0, 1, 3, 4, 7, 8], [0, 1, 3, 4, 7, 8, 9], [0, 1, 3, 4, 7, 9], [0, 1, 3, 4, 8], [0, 1, 3, 4, 8, 9], [0, 1, 3, 4, 9], [0, 1, 3, 5], [0, 1, 3, 5, 6], [0, 1, 3, 5, 6, 7], [0, 1, 3, 5, 6, 7, 8], [0, 1, 3, 5, 6, 7, 8, 9], [0, 1, 3, 5, 6, 7, 9], [0, 1, 3, 5, 6, 8], [0, 1, 3, 5, 6, 8, 9], [0, 1, 3, 5, 6, 9], [0, 1, 3, 5, 7], [0, 1, 3, 5, 7, 8], [0, 1, 3, 5, 7, 8, 9], [0, 1, 3, 5, 7, 9], [0, 1, 3, 5, 8], [0, 1, 3, 5, 8, 9], [0, 1, 3, 5, 9], [0, 1, 3, 6], [0, 1, 3, 6, 7], [0, 1, 3, 6, 7, 8], [0, 1, 3, 6, 7, 8, 9], [0, 1, 3, 6, 7, 9], [0, 1, 3, 6, 8], [0, 1, 3, 6, 8, 9], [0, 1, 3, 6, 9], [0, 1, 3, 7], [0, 1, 3, 7, 8], [0, 1, 3, 7, 8, 9], [0, 1, 3, 7, 9], [0, 1, 3, 8], [0, 1, 3, 8, 9], [0, 1, 3, 9], [0, 1, 4], [0, 1, 4, 5], [0, 1, 4, 5, 6], [0, 1, 4, 5, 6, 7], [0, 1, 4, 5, 6, 7, 8], [0, 1, 4, 5, 6, 7, 8, 9], [0, 1, 4, 5, 6, 7, 9], [0, 1, 4, 5, 6, 8], [0, 1, 4, 5, 6, 8, 9], [0, 1, 4, 5, 6, 9], [0, 1, 4, 5, 7], [0, 1, 4, 5, 7, 8], [0, 1, 4, 5, 7, 8, 9], [0, 1, 4, 5, 7, 9], [0, 1, 4, 5, 8], [0, 1, 4, 5, 8, 9], [0, 1, 4, 5, 9], [0, 1, 4, 6], [0, 1, 4, 6, 7], [0, 1, 4, 6, 7, 8], [0, 1, 4, 6, 7, 8, 9], [0, 1, 4, 6, 7, 9], [0, 1, 4, 6, 8], [0, 1, 4, 6, 8, 9], [0, 1, 4, 6, 9], [0, 1, 4, 7], [0, 1, 4, 7, 8], [0, 1, 4, 7, 8, 9], [0, 1, 4, 7, 9], [0, 1, 4, 8], [0, 1, 4, 8, 9], [0, 1, 4, 9], [0, 1, 5], [0, 1, 5, 6], [0, 1, 5, 6, 7], [0, 1, 5, 6, 7, 8], [0, 1, 5, 6, 7, 8, 9], [0, 1, 5, 6, 7, 9], [0, 1, 5, 6, 8], [0, 1, 5, 6, 8, 9], [0, 1, 5, 6, 9], [0, 1, 5, 7], [0, 1, 5, 7, 8], [0, 1, 5, 7, 8, 9], [0, 1, 5, 7, 9], [0, 1, 5, 8], [0, 1, 5, 8, 9], [0, 1, 5, 9], [0, 1, 6], [0, 1, 6, 7], [0, 1, 6, 7, 8], [0, 1, 6, 7, 8, 9], [0, 1, 6, 7, 9], [0, 1, 6, 8], [0, 1, 6, 8, 9], [0, 1, 6, 9], [0, 1, 7], [0, 1, 7, 8], [0, 1, 7, 8, 9], [0, 1, 7, 9], [0, 1, 8], [0, 1, 8, 9], [0, 1, 9], [0, 2], [0, 2, 3], [0, 2, 3, 4], [0, 2, 3, 4, 5], [0, 2, 3, 4, 5, 6], [0, 2, 3, 4, 5, 6, 7], [0, 2, 3, 4, 5, 6, 7, 8], [0, 2, 3, 4, 5, 6, 7, 8, 9], [0, 2, 3, 4, 5, 6, 7, 9], [0, 2, 3, 4, 5, 6, 8], [0, 2, 3, 4, 5, 6, 8, 9], [0, 2, 3, 4, 5, 6, 9], [0, 2, 3, 4, 5, 7], [0, 2, 3, 4, 5, 7, 8], [0, 2, 3, 4, 5, 7, 8, 9], [0, 2, 3, 4, 5, 7, 9], [0, 2, 3, 4, 5, 8], [0, 2, 3, 4, 5, 8, 9], [0, 2, 3, 4, 5, 9], [0, 2, 3, 4, 6], [0, 2, 3, 4, 6, 7], [0, 2, 3, 4, 6, 7, 8], [0, 2, 3, 4, 6, 7, 8, 9], [0, 2, 3, 4, 6, 7, 9], [0, 2, 3, 4, 6, 8], [0, 2, 3, 4, 6, 8, 9], [0, 2, 3, 4, 6, 9], [0, 2, 3, 4, 7], [0, 2, 3, 4, 7, 8], [0, 2, 3, 4, 7, 8, 9], [0, 2, 3, 4, 7, 9], [0, 2, 3, 4, 8], [0, 2, 3, 4, 8, 9], [0, 2, 3, 4, 9], [0, 2, 3, 5], [0, 2, 3, 5, 6], [0, 2, 3, 5, 6, 7], [0, 2, 3, 5, 6, 7, 8], [0, 2, 3, 5, 6, 7, 8, 9], [0, 2, 3, 5, 6, 7, 9], [0, 2, 3, 5, 6, 8], [0, 2, 3, 5, 6, 8, 9], [0, 2, 3, 5, 6, 9], [0, 2, 3, 5, 7], [0, 2, 3, 5, 7, 8], [0, 2, 3, 5, 7, 8, 9], [0, 2, 3, 5, 7, 9], [0, 2, 3, 5, 8], [0, 2, 3, 5, 8, 9], [0, 2, 3, 5, 9], [0, 2, 3, 6], [0, 2, 3, 6, 7], [0, 2, 3, 6, 7, 8], [0, 2, 3, 6, 7, 8, 9], [0, 2, 3, 6, 7, 9], [0, 2, 3, 6, 8], [0, 2, 3, 6, 8, 9], [0, 2, 3, 6, 9], [0, 2, 3, 7], [0, 2, 3, 7, 8], [0, 2, 3, 7, 8, 9], [0, 2, 3, 7, 9], [0, 2, 3, 8], [0, 2, 3, 8, 9], [0, 2, 3, 9], [0, 2, 4], [0, 2, 4, 5], [0, 2, 4, 5, 6], [0, 2, 4, 5, 6, 7], [0, 2, 4, 5, 6, 7, 8], [0, 2, 4, 5, 6, 7, 8, 9], [0, 2, 4, 5, 6, 7, 9], [0, 2, 4, 5, 6, 8], [0, 2, 4, 5, 6, 8, 9], [0, 2, 4, 5, 6, 9], [0, 2, 4, 5, 7], [0, 2, 4, 5, 7, 8], [0, 2, 4, 5, 7, 8, 9], [0, 2, 4, 5, 7, 9], [0, 2, 4, 5, 8], [0, 2, 4, 5, 8, 9], [0, 2, 4, 5, 9], [0, 2, 4, 6], [0, 2, 4, 6, 7], [0, 2, 4, 6, 7, 8], [0, 2, 4, 6, 7, 8, 9], [0, 2, 4, 6, 7, 9], [0, 2, 4, 6, 8], [0, 2, 4, 6, 8, 9], [0, 2, 4, 6, 9], [0, 2, 4, 7], [0, 2, 4, 7, 8], [0, 2, 4, 7, 8, 9], [0, 2, 4, 7, 9], [0, 2, 4, 8], [0, 2, 4, 8, 9], [0, 2, 4, 9], [0, 2, 5], [0, 2, 5, 6], [0, 2, 5, 6, 7], [0, 2, 5, 6, 7, 8], [0, 2, 5, 6, 7, 8, 9], [0, 2, 5, 6, 7, 9], [0, 2, 5, 6, 8], [0, 2, 5, 6, 8, 9], [0, 2, 5, 6, 9], [0, 2, 5, 7], [0, 2, 5, 7, 8], [0, 2, 5, 7, 8, 9], [0, 2, 5, 7, 9], [0, 2, 5, 8], [0, 2, 5, 8, 9], [0, 2, 5, 9], [0, 2, 6], [0, 2, 6, 7], [0, 2, 6, 7, 8], [0, 2, 6, 7, 8, 9], [0, 2, 6, 7, 9], [0, 2, 6, 8], [0, 2, 6, 8, 9], [0, 2, 6, 9], [0, 2, 7], [0, 2, 7, 8], [0, 2, 7, 8, 9], [0, 2, 7, 9], [0, 2, 8], [0, 2, 8, 9], [0, 2, 9], [0, 3], [0, 3, 4], [0, 3, 4, 5], [0, 3, 4, 5, 6], [0, 3, 4, 5, 6, 7], [0, 3, 4, 5, 6, 7, 8], [0, 3, 4, 5, 6, 7, 8, 9], [0, 3, 4, 5, 6, 7, 9], [0, 3, 4, 5, 6, 8], [0, 3, 4, 5, 6, 8, 9], [0, 3, 4, 5, 6, 9], [0, 3, 4, 5, 7], [0, 3, 4, 5, 7, 8], [0, 3, 4, 5, 7, 8, 9], [0, 3, 4, 5, 7, 9], [0, 3, 4, 5, 8], [0, 3, 4, 5, 8, 9], [0, 3, 4, 5, 9], [0, 3, 4, 6], [0, 3, 4, 6, 7], [0, 3, 4, 6, 7, 8], [0, 3, 4, 6, 7, 8, 9], [0, 3, 4, 6, 7, 9], [0, 3, 4, 6, 8], [0, 3, 4, 6, 8, 9], [0, 3, 4, 6, 9], [0, 3, 4, 7], [0, 3, 4, 7, 8], [0, 3, 4, 7, 8, 9], [0, 3, 4, 7, 9], [0, 3, 4, 8], [0, 3, 4, 8, 9], [0, 3, 4, 9], [0, 3, 5], [0, 3, 5, 6], [0, 3, 5, 6, 7], [0, 3, 5, 6, 7, 8], [0, 3, 5, 6, 7, 8, 9], [0, 3, 5, 6, 7, 9], [0, 3, 5, 6, 8], [0, 3, 5, 6, 8, 9], [0, 3, 5, 6, 9], [0, 3, 5, 7], [0, 3, 5, 7, 8], [0, 3, 5, 7, 8, 9], [0, 3, 5, 7, 9], [0, 3, 5, 8], [0, 3, 5, 8, 9], [0, 3, 5, 9], [0, 3, 6], [0, 3, 6, 7], [0, 3, 6, 7, 8], [0, 3, 6, 7, 8, 9], [0, 3, 6, 7, 9], [0, 3, 6, 8], [0, 3, 6, 8, 9], [0, 3, 6, 9], [0, 3, 7], [0, 3, 7, 8], [0, 3, 7, 8, 9], [0, 3, 7, 9], [0, 3, 8], [0, 3, 8, 9], [0, 3, 9], [0, 4], [0, 4, 5], [0, 4, 5, 6], [0, 4, 5, 6, 7], [0, 4, 5, 6, 7, 8], [0, 4, 5, 6, 7, 8, 9], [0, 4, 5, 6, 7, 9], [0, 4, 5, 6, 8], [0, 4, 5, 6, 8, 9], [0, 4, 5, 6, 9], [0, 4, 5, 7], [0, 4, 5, 7, 8], [0, 4, 5, 7, 8, 9], [0, 4, 5, 7, 9], [0, 4, 5, 8], [0, 4, 5, 8, 9], [0, 4, 5, 9], [0, 4, 6], [0, 4, 6, 7], [0, 4, 6, 7, 8], [0, 4, 6, 7, 8, 9], [0, 4, 6, 7, 9], [0, 4, 6, 8], [0, 4, 6, 8, 9], [0, 4, 6, 9], [0, 4, 7], [0, 4, 7, 8], [0, 4, 7, 8, 9], [0, 4, 7, 9], [0, 4, 8], [0, 4, 8, 9], [0, 4, 9], [0, 5], [0, 5, 6], [0, 5, 6, 7], [0, 5, 6, 7, 8], [0, 5, 6, 7, 8, 9], [0, 5, 6, 7, 9], [0, 5, 6, 8], [0, 5, 6, 8, 9], [0, 5, 6, 9], [0, 5, 7], [0, 5, 7, 8], [0, 5, 7, 8, 9], [0, 5, 7, 9], [0, 5, 8], [0, 5, 8, 9], [0, 5, 9], [0, 6], [0, 6, 7], [0, 6, 7, 8], [0, 6, 7, 8, 9], [0, 6, 7, 9], [0, 6, 8], [0, 6, 8, 9], [0, 6, 9], [0, 7], [0, 7, 8], [0, 7, 8, 9], [0, 7, 9], [0, 8], [0, 8, 9], [0, 9], [1], [1, 2], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6, 7], [1, 2, 3, 4, 5, 6, 7, 8], [1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 2, 3, 4, 5, 6, 7, 9], [1, 2, 3, 4, 5, 6, 8], [1, 2, 3, 4, 5, 6, 8, 9], [1, 2, 3, 4, 5, 6, 9], [1, 2, 3, 4, 5, 7], [1, 2, 3, 4, 5, 7, 8], [1, 2, 3, 4, 5, 7, 8, 9], [1, 2, 3, 4, 5, 7, 9], [1, 2, 3, 4, 5, 8], [1, 2, 3, 4, 5, 8, 9], [1, 2, 3, 4, 5, 9], [1, 2, 3, 4, 6], [1, 2, 3, 4, 6, 7], [1, 2, 3, 4, 6, 7, 8], [1, 2, 3, 4, 6, 7, 8, 9], [1, 2, 3, 4, 6, 7, 9], [1, 2, 3, 4, 6, 8], [1, 2, 3, 4, 6, 8, 9], [1, 2, 3, 4, 6, 9], [1, 2, 3, 4, 7], [1, 2, 3, 4, 7, 8], [1, 2, 3, 4, 7, 8, 9], [1, 2, 3, 4, 7, 9], [1, 2, 3, 4, 8], [1, 2, 3, 4, 8, 9], [1, 2, 3, 4, 9], [1, 2, 3, 5], [1, 2, 3, 5, 6], [1, 2, 3, 5, 6, 7], [1, 2, 3, 5, 6, 7, 8], [1, 2, 3, 5, 6, 7, 8, 9], [1, 2, 3, 5, 6, 7, 9], [1, 2, 3, 5, 6, 8], [1, 2, 3, 5, 6, 8, 9], [1, 2, 3, 5, 6, 9], [1, 2, 3, 5, 7], [1, 2, 3, 5, 7, 8], [1, 2, 3, 5, 7, 8, 9], [1, 2, 3, 5, 7, 9], [1, 2, 3, 5, 8], [1, 2, 3, 5, 8, 9], [1, 2, 3, 5, 9], [1, 2, 3, 6], [1, 2, 3, 6, 7], [1, 2, 3, 6, 7, 8], [1, 2, 3, 6, 7, 8, 9], [1, 2, 3, 6, 7, 9], [1, 2, 3, 6, 8], [1, 2, 3, 6, 8, 9], [1, 2, 3, 6, 9], [1, 2, 3, 7], [1, 2, 3, 7, 8], [1, 2, 3, 7, 8, 9], [1, 2, 3, 7, 9], [1, 2, 3, 8], [1, 2, 3, 8, 9], [1, 2, 3, 9], [1, 2, 4], [1, 2, 4, 5], [1, 2, 4, 5, 6], [1, 2, 4, 5, 6, 7], [1, 2, 4, 5, 6, 7, 8], [1, 2, 4, 5, 6, 7, 8, 9], [1, 2, 4, 5, 6, 7, 9], [1, 2, 4, 5, 6, 8], [1, 2, 4, 5, 6, 8, 9], [1, 2, 4, 5, 6, 9], [1, 2, 4, 5, 7], [1, 2, 4, 5, 7, 8], [1, 2, 4, 5, 7, 8, 9], [1, 2, 4, 5, 7, 9], [1, 2, 4, 5, 8], [1, 2, 4, 5, 8, 9], [1, 2, 4, 5, 9], [1, 2, 4, 6], [1, 2, 4, 6, 7], [1, 2, 4, 6, 7, 8], [1, 2, 4, 6, 7, 8, 9], [1, 2, 4, 6, 7, 9], [1, 2, 4, 6, 8], [1, 2, 4, 6, 8, 9], [1, 2, 4, 6, 9], [1, 2, 4, 7], [1, 2, 4, 7, 8], [1, 2, 4, 7, 8, 9], [1, 2, 4, 7, 9], [1, 2, 4, 8], [1, 2, 4, 8, 9], [1, 2, 4, 9], [1, 2, 5], [1, 2, 5, 6], [1, 2, 5, 6, 7], [1, 2, 5, 6, 7, 8], [1, 2, 5, 6, 7, 8, 9], [1, 2, 5, 6, 7, 9], [1, 2, 5, 6, 8], [1, 2, 5, 6, 8, 9], [1, 2, 5, 6, 9], [1, 2, 5, 7], [1, 2, 5, 7, 8], [1, 2, 5, 7, 8, 9], [1, 2, 5, 7, 9], [1, 2, 5, 8], [1, 2, 5, 8, 9], [1, 2, 5, 9], [1, 2, 6], [1, 2, 6, 7], [1, 2, 6, 7, 8], [1, 2, 6, 7, 8, 9], [1, 2, 6, 7, 9], [1, 2, 6, 8], [1, 2, 6, 8, 9], [1, 2, 6, 9], [1, 2, 7], [1, 2, 7, 8], [1, 2, 7, 8, 9], [1, 2, 7, 9], [1, 2, 8], [1, 2, 8, 9], [1, 2, 9], [1, 3], [1, 3, 4], [1, 3, 4, 5], [1, 3, 4, 5, 6], [1, 3, 4, 5, 6, 7], [1, 3, 4, 5, 6, 7, 8], [1, 3, 4, 5, 6, 7, 8, 9], [1, 3, 4, 5, 6, 7, 9], [1, 3, 4, 5, 6, 8], [1, 3, 4, 5, 6, 8, 9], [1, 3, 4, 5, 6, 9], [1, 3, 4, 5, 7], [1, 3, 4, 5, 7, 8], [1, 3, 4, 5, 7, 8, 9], [1, 3, 4, 5, 7, 9], [1, 3, 4, 5, 8], [1, 3, 4, 5, 8, 9], [1, 3, 4, 5, 9], [1, 3, 4, 6], [1, 3, 4, 6, 7], [1, 3, 4, 6, 7, 8], [1, 3, 4, 6, 7, 8, 9], [1, 3, 4, 6, 7, 9], [1, 3, 4, 6, 8], [1, 3, 4, 6, 8, 9], [1, 3, 4, 6, 9], [1, 3, 4, 7], [1, 3, 4, 7, 8], [1, 3, 4, 7, 8, 9], [1, 3, 4, 7, 9], [1, 3, 4, 8], [1, 3, 4, 8, 9], [1, 3, 4, 9], [1, 3, 5], [1, 3, 5, 6], [1, 3, 5, 6, 7], [1, 3, 5, 6, 7, 8], [1, 3, 5, 6, 7, 8, 9], [1, 3, 5, 6, 7, 9], [1, 3, 5, 6, 8], [1, 3, 5, 6, 8, 9], [1, 3, 5, 6, 9], [1, 3, 5, 7], [1, 3, 5, 7, 8], [1, 3, 5, 7, 8, 9], [1, 3, 5, 7, 9], [1, 3, 5, 8], [1, 3, 5, 8, 9], [1, 3, 5, 9], [1, 3, 6], [1, 3, 6, 7], [1, 3, 6, 7, 8], [1, 3, 6, 7, 8, 9], [1, 3, 6, 7, 9], [1, 3, 6, 8], [1, 3, 6, 8, 9], [1, 3, 6, 9], [1, 3, 7], [1, 3, 7, 8], [1, 3, 7, 8, 9], [1, 3, 7, 9], [1, 3, 8], [1, 3, 8, 9], [1, 3, 9], [1, 4], [1, 4, 5], [1, 4, 5, 6], [1, 4, 5, 6, 7], [1, 4, 5, 6, 7, 8], [1, 4, 5, 6, 7, 8, 9], [1, 4, 5, 6, 7, 9], [1, 4, 5, 6, 8], [1, 4, 5, 6, 8, 9], [1, 4, 5, 6, 9], [1, 4, 5, 7], [1, 4, 5, 7, 8], [1, 4, 5, 7, 8, 9], [1, 4, 5, 7, 9], [1, 4, 5, 8], [1, 4, 5, 8, 9], [1, 4, 5, 9], [1, 4, 6], [1, 4, 6, 7], [1, 4, 6, 7, 8], [1, 4, 6, 7, 8, 9], [1, 4, 6, 7, 9], [1, 4, 6, 8], [1, 4, 6, 8, 9], [1, 4, 6, 9], [1, 4, 7], [1, 4, 7, 8], [1, 4, 7, 8, 9], [1, 4, 7, 9], [1, 4, 8], [1, 4, 8, 9], [1, 4, 9], [1, 5], [1, 5, 6], [1, 5, 6, 7], [1, 5, 6, 7, 8], [1, 5, 6, 7, 8, 9], [1, 5, 6, 7, 9], [1, 5, 6, 8], [1, 5, 6, 8, 9], [1, 5, 6, 9], [1, 5, 7], [1, 5, 7, 8], [1, 5, 7, 8, 9], [1, 5, 7, 9], [1, 5, 8], [1, 5, 8, 9], [1, 5, 9], [1, 6], [1, 6, 7], [1, 6, 7, 8], [1, 6, 7, 8, 9], [1, 6, 7, 9], [1, 6, 8], [1, 6, 8, 9], [1, 6, 9], [1, 7], [1, 7, 8], [1, 7, 8, 9], [1, 7, 9], [1, 8], [1, 8, 9], [1, 9], [2], [2, 3], [2, 3, 4], [2, 3, 4, 5], [2, 3, 4, 5, 6], [2, 3, 4, 5, 6, 7], [2, 3, 4, 5, 6, 7, 8], [2, 3, 4, 5, 6, 7, 8, 9], [2, 3, 4, 5, 6, 7, 9], [2, 3, 4, 5, 6, 8], [2, 3, 4, 5, 6, 8, 9], [2, 3, 4, 5, 6, 9], [2, 3, 4, 5, 7], [2, 3, 4, 5, 7, 8], [2, 3, 4, 5, 7, 8, 9], [2, 3, 4, 5, 7, 9], [2, 3, 4, 5, 8], [2, 3, 4, 5, 8, 9], [2, 3, 4, 5, 9], [2, 3, 4, 6], [2, 3, 4, 6, 7], [2, 3, 4, 6, 7, 8], [2, 3, 4, 6, 7, 8, 9], [2, 3, 4, 6, 7, 9], [2, 3, 4, 6, 8], [2, 3, 4, 6, 8, 9], [2, 3, 4, 6, 9], [2, 3, 4, 7], [2, 3, 4, 7, 8], [2, 3, 4, 7, 8, 9], [2, 3, 4, 7, 9], [2, 3, 4, 8], [2, 3, 4, 8, 9], [2, 3, 4, 9], [2, 3, 5], [2, 3, 5, 6], [2, 3, 5, 6, 7], [2, 3, 5, 6, 7, 8], [2, 3, 5, 6, 7, 8, 9], [2, 3, 5, 6, 7, 9], [2, 3, 5, 6, 8], [2, 3, 5, 6, 8, 9], [2, 3, 5, 6, 9], [2, 3, 5, 7], [2, 3, 5, 7, 8], [2, 3, 5, 7, 8, 9], [2, 3, 5, 7, 9], [2, 3, 5, 8], [2, 3, 5, 8, 9], [2, 3, 5, 9], [2, 3, 6], [2, 3, 6, 7], [2, 3, 6, 7, 8], [2, 3, 6, 7, 8, 9], [2, 3, 6, 7, 9], [2, 3, 6, 8], [2, 3, 6, 8, 9], [2, 3, 6, 9], [2, 3, 7], [2, 3, 7, 8], [2, 3, 7, 8, 9], [2, 3, 7, 9], [2, 3, 8], [2, 3, 8, 9], [2, 3, 9], [2, 4], [2, 4, 5], [2, 4, 5, 6], [2, 4, 5, 6, 7], [2, 4, 5, 6, 7, 8], [2, 4, 5, 6, 7, 8, 9], [2, 4, 5, 6, 7, 9], [2, 4, 5, 6, 8], [2, 4, 5, 6, 8, 9], [2, 4, 5, 6, 9], [2, 4, 5, 7], [2, 4, 5, 7, 8], [2, 4, 5, 7, 8, 9], [2, 4, 5, 7, 9], [2, 4, 5, 8], [2, 4, 5, 8, 9], [2, 4, 5, 9], [2, 4, 6], [2, 4, 6, 7], [2, 4, 6, 7, 8], [2, 4, 6, 7, 8, 9], [2, 4, 6, 7, 9], [2, 4, 6, 8], [2, 4, 6, 8, 9], [2, 4, 6, 9], [2, 4, 7], [2, 4, 7, 8], [2, 4, 7, 8, 9], [2, 4, 7, 9], [2, 4, 8], [2, 4, 8, 9], [2, 4, 9], [2, 5], [2, 5, 6], [2, 5, 6, 7], [2, 5, 6, 7, 8], [2, 5, 6, 7, 8, 9], [2, 5, 6, 7, 9], [2, 5, 6, 8], [2, 5, 6, 8, 9], [2, 5, 6, 9], [2, 5, 7], [2, 5, 7, 8], [2, 5, 7, 8, 9], [2, 5, 7, 9], [2, 5, 8], [2, 5, 8, 9], [2, 5, 9], [2, 6], [2, 6, 7], [2, 6, 7, 8], [2, 6, 7, 8, 9], [2, 6, 7, 9], [2, 6, 8], [2, 6, 8, 9], [2, 6, 9], [2, 7], [2, 7, 8], [2, 7, 8, 9], [2, 7, 9], [2, 8], [2, 8, 9], [2, 9], [3], [3, 4], [3, 4, 5], [3, 4, 5, 6], [3, 4, 5, 6, 7], [3, 4, 5, 6, 7, 8], [3, 4, 5, 6, 7, 8, 9], [3, 4, 5, 6, 7, 9], [3, 4, 5, 6, 8], [3, 4, 5, 6, 8, 9], [3, 4, 5, 6, 9], [3, 4, 5, 7], [3, 4, 5, 7, 8], [3, 4, 5, 7, 8, 9], [3, 4, 5, 7, 9], [3, 4, 5, 8], [3, 4, 5, 8, 9], [3, 4, 5, 9], [3, 4, 6], [3, 4, 6, 7], [3, 4, 6, 7, 8], [3, 4, 6, 7, 8, 9], [3, 4, 6, 7, 9], [3, 4, 6, 8], [3, 4, 6, 8, 9], [3, 4, 6, 9], [3, 4, 7], [3, 4, 7, 8], [3, 4, 7, 8, 9], [3, 4, 7, 9], [3, 4, 8], [3, 4, 8, 9], [3, 4, 9], [3, 5], [3, 5, 6], [3, 5, 6, 7], [3, 5, 6, 7, 8], [3, 5, 6, 7, 8, 9], [3, 5, 6, 7, 9], [3, 5, 6, 8], [3, 5, 6, 8, 9], [3, 5, 6, 9], [3, 5, 7], [3, 5, 7, 8], [3, 5, 7, 8, 9], [3, 5, 7, 9], [3, 5, 8], [3, 5, 8, 9], [3, 5, 9], [3, 6], [3, 6, 7], [3, 6, 7, 8], [3, 6, 7, 8, 9], [3, 6, 7, 9], [3, 6, 8], [3, 6, 8, 9], [3, 6, 9], [3, 7], [3, 7, 8], [3, 7, 8, 9], [3, 7, 9], [3, 8], [3, 8, 9], [3, 9], [4], [4, 5], [4, 5, 6], [4, 5, 6, 7], [4, 5, 6, 7, 8], [4, 5, 6, 7, 8, 9], [4, 5, 6, 7, 9], [4, 5, 6, 8], [4, 5, 6, 8, 9], [4, 5, 6, 9], [4, 5, 7], [4, 5, 7, 8], [4, 5, 7, 8, 9], [4, 5, 7, 9], [4, 5, 8], [4, 5, 8, 9], [4, 5, 9], [4, 6], [4, 6, 7], [4, 6, 7, 8], [4, 6, 7, 8, 9], [4, 6, 7, 9], [4, 6, 8], [4, 6, 8, 9], [4, 6, 9], [4, 7], [4, 7, 8], [4, 7, 8, 9], [4, 7, 9], [4, 8], [4, 8, 9], [4, 9], [5], [5, 6], [5, 6, 7], [5, 6, 7, 8], [5, 6, 7, 8, 9], [5, 6, 7, 9], [5, 6, 8], [5, 6, 8, 9], [5, 6, 9], [5, 7], [5, 7, 8], [5, 7, 8, 9], [5, 7, 9], [5, 8], [5, 8, 9], [5, 9], [6], [6, 7], [6, 7, 8], [6, 7, 8, 9], [6, 7, 9], [6, 8], [6, 8, 9], [6, 9], [7], [7, 8], [7, 8, 9], [7, 9], [8], [8, 9], [9]]\n",
            "1023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL4ZqMMEG600",
        "outputId": "d2e2f16b-0558-4f53-9403-afcc91091910"
      },
      "source": [
        "utility_matrix = np.zeros([len(act_set), len(class_set)])\n",
        "tol_i = 3 \n",
        "#tol_i = 0 with tol=0.5, tol_i = 1 with tol=0.6, tol_i = 2 with tol=0.7, tol_i = 3 with tol=0.8, tol_i = 4 with tol=0.9\n",
        "for i in range(len(act_set)):\n",
        "  intersec = class_set and act_set[i]\n",
        "  if len(intersec) == 1:\n",
        "    utility_matrix[i, intersec] = 1\n",
        "  \n",
        "  else:\n",
        "    for j in range(len(intersec)):\n",
        "      utility_matrix[i, intersec[j]] = locals()['weight'+str(len(intersec))][tol_i, 0]\n",
        "print (utility_matrix)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.8        0.8        0.         ... 0.         0.         0.        ]\n",
            " [0.68208412 0.68208412 0.68208412 ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         1.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.8        0.8       ]\n",
            " [0.         0.         0.         ... 0.         0.         1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HgXjy46KVuW"
      },
      "source": [
        "Let's build the evidential FitNet-4 classifier for set-valued classification. Compared to the classifier with only precise classification, the testing classifier have extra expected utilities for all imprecise assignments if considering all possible subsets. Thus, we can directly get the weights from the previous classifiers without extra training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWJPNHxddFy5",
        "outputId": "eaca7eb4-f933-4fb1-928b-a94c68fa5d87"
      },
      "source": [
        "IMG_WIDTH = 32\n",
        "IMG_HEIGHT = 32\n",
        "IMG_CHANNELS = 3\n",
        "inputs_pixels = IMG_WIDTH * IMG_HEIGHT\n",
        "prototypes=200\n",
        "num_class=10\n",
        "number_act_set = len(act_set)\n",
        "\n",
        "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "\n",
        "#convolution stages\n",
        "c1_1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "c1_2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_1)\n",
        "c1_3 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_2)\n",
        "c1_4 = tf.keras.layers.Conv2D(48, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_3)\n",
        "c1_5 = tf.keras.layers.Conv2D(48, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1_4)\n",
        "bt1 = tf.keras.layers.BatchNormalization()(c1_5)\n",
        "p1 = tf.keras.layers.MaxPooling2D((2, 2))(bt1)\n",
        "dr1 = tf.keras.layers.Dropout(0.5)(p1)\n",
        "\n",
        "\n",
        "c2_1 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(dr1)\n",
        "c2_2 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_1)\n",
        "c2_3 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_2)\n",
        "c2_4 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_3)\n",
        "c2_5 = tf.keras.layers.Conv2D(80, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2_4)\n",
        "bt2 = tf.keras.layers.BatchNormalization()(c2_5)\n",
        "p2 = tf.keras.layers.MaxPooling2D((2, 2))(bt2)\n",
        "dr2 = tf.keras.layers.Dropout(0.5)(p2)\n",
        "\n",
        "c3_1 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(dr2)\n",
        "c3_2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_1)\n",
        "c3_3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_2)\n",
        "c3_4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_3)\n",
        "c3_5 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3_4)\n",
        "bt3 = tf.keras.layers.BatchNormalization()(c3_5)\n",
        "p3 = tf.keras.layers.MaxPooling2D((8, 8))(bt3)\n",
        "dr3 = tf.keras.layers.Dropout(0.5)(p3)\n",
        "flatten1=tf.keras.layers.Flatten()(dr3)\n",
        "\n",
        "#DS layer\n",
        "ED = ds_layer.DS1(prototypes,128)(flatten1)\n",
        "ED_ac = ds_layer.DS1_activate(prototypes)(ED)\n",
        "mass_prototypes = ds_layer.DS2(prototypes, num_class)(ED_ac)\n",
        "mass_prototypes_omega = ds_layer.DS2_omega(prototypes, num_class)(mass_prototypes)\n",
        "mass_Dempster = ds_layer.DS3_Dempster(prototypes, num_class)(mass_prototypes_omega)\n",
        "mass_Dempster_normalize = ds_layer.DS3_normalize()(mass_Dempster)\n",
        "\n",
        "#Utility layer for testing\n",
        "outputs = utility_layer_test.DM_test(num_class, number_act_set, 0.9)(mass_Dempster_normalize)\n",
        "\n",
        "\n",
        "model_e_imprecise = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
        "model_e_imprecise.compile(optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004), \n",
        "              loss='CategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_e_imprecise.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_105 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 32, 32, 48)        13872     \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 32, 32, 48)        20784     \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 32, 32, 48)        192       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 16, 16, 48)        0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 16, 16, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 16, 16, 80)        34640     \n",
            "_________________________________________________________________\n",
            "conv2d_111 (Conv2D)          (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "conv2d_114 (Conv2D)          (None, 16, 16, 80)        57680     \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 16, 16, 80)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 8, 8, 80)          0         \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 8, 8, 80)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 8, 8, 128)         92288     \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_117 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "d_s1_16 (DS1)                (None, 200)               25600     \n",
            "_________________________________________________________________\n",
            "d_s1_activate_16 (DS1_activa (None, 200)               400       \n",
            "_________________________________________________________________\n",
            "d_s2_16 (DS2)                (None, 200, 10)           2000      \n",
            "_________________________________________________________________\n",
            "d_s2_omega_16 (DS2_omega)    (None, 200, 11)           0         \n",
            "_________________________________________________________________\n",
            "d_s3__dempster_16 (DS3_Demps (None, 11)                0         \n",
            "_________________________________________________________________\n",
            "d_s3_normalize_16 (DS3_norma (None, 11)                0         \n",
            "_________________________________________________________________\n",
            "dm_test (DM_test)            (None, 1023)              10230     \n",
            "=================================================================\n",
            "Total params: 1,041,286\n",
            "Trainable params: 1,030,544\n",
            "Non-trainable params: 10,742\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a46jzvkjH6N"
      },
      "source": [
        "model_e_imprecise.layers[-1].set_weights(tf.reshape(utility_matrix, [1, 1023, 10]))\n",
        "model_e_imprecise.load_weights('/content/gdrive/My Drive/cifar10_evidential/weights_zoo/evidential_DL_200_checkpoint')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niM7_jS5o2bz"
      },
      "source": [
        "When the tolerance of imprecision equals to 0.8, the average utility is higher than the one in precise classification, and we can find some samples that are mis-classified in the precise classification are assigned into the multi-class sets, which includes the true labels, such as sample 37 and 128."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiHmgcs-jrcp",
        "outputId": "c3e3bfa4-10f3-4147-e2f7-fb122b83c661"
      },
      "source": [
        "resutls = tf.argmax(model_e_imprecise.predict(x_test),-1)\n",
        "imprecise_results =[]\n",
        "for i in range(len(resutls)):\n",
        "  act_local = resutls[i]\n",
        "  set_valued_results = act_set[act_local]\n",
        "  imprecise_results.append(set_valued_results)\n",
        "print (imprecise_results)\n",
        "average_utility_imprecision = AU_imprecision.average_utility(utility_matrix, resutls, y_test_label, act_set)\n",
        "print (average_utility_imprecision)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3], [8], [1], [0], [6], [6], [1], [2, 6, 9], [3], [1], [0], [9], [5], [7], [9], [8], [5], [7], [8], [6], [3, 7], [2], [4], [9], [4, 7], [2, 4, 7], [3], [0], [9], [6], [6], [5], [4, 6], [5], [9], [2, 6, 8], [4], [1], [9], [5], [0, 4], [6], [5], [6], [0], [9], [3], [9], [7], [6], [9], [8], [0], [3], [8], [8], [7], [3], [4], [0, 3, 4], [7], [7], [6], [3], [6], [2], [1], [2], [3], [7], [2], [6], [8], [8], [0], [2, 9], [9], [3], [5], [8], [8], [1], [1], [7], [2], [5], [2], [7], [8], [9], [0], [3], [8], [6], [4], [6], [6], [0], [0], [7], [4], [5], [6], [3], [1], [1], [3], [6], [8], [7], [4], [0], [6], [2], [1], [3], [0], [4], [2, 6], [7], [8], [3], [1], [2], [8], [0], [8], [3], [0, 4], [2], [4], [1], [8], [9], [1], [2], [9], [7], [2], [1], [6], [5], [6], [3], [8], [7], [6], [5], [5], [2], [8], [9], [6], [0], [0], [5], [2], [9], [2, 3], [4], [2], [1], [6], [6], [0], [4], [8], [4], [5], [8], [9], [0, 9], [9], [2, 6, 8], [9], [9], [3], [7], [5], [0], [0], [5], [2], [2], [3], [8], [2, 6], [3], [0, 3, 4], [0], [5], [8], [0, 4], [1], [7], [2, 9], [8], [8], [7], [8], [5], [1], [8], [7], [1], [3], [0], [5], [7], [9], [7], [0, 4], [5], [2, 8], [8], [2], [7], [9], [8], [2], [7], [6], [9], [4], [3], [9], [8], [4], [7], [6], [5], [1], [3], [8], [8], [0], [4], [0, 2, 9], [5], [5], [1], [1], [1, 8], [9], [0], [2, 3, 8], [1], [2, 8, 9], [2], [2], [5], [3], [9], [9], [4], [0, 8], [3], [0], [0], [9], [8], [1], [5], [7], [0], [8], [2], [4], [7], [0, 2], [2], [3], [6], [3], [8], [3], [0], [3], [4], [6], [9], [0], [6], [1], [0], [9], [1], [0], [7], [9], [1], [2, 9], [6], [9], [3], [4], [6], [0], [0], [6], [6], [6], [3], [2], [6], [1], [1, 8], [2], [1], [2], [8], [6], [0], [2], [4], [0], [7], [7], [5], [5], [3], [5], [2], [3], [4], [1], [7], [5], [4], [6], [1], [9], [3], [2, 6], [6], [9], [3], [8], [0], [7], [2], [6], [2], [5], [8], [5], [4], [6], [8], [9], [9], [1], [0], [2], [2], [4], [6], [2], [8], [0], [9], [5], [8], [1], [9], [4], [9], [3], [2, 6, 8], [1], [0, 4], [7], [9], [4], [2, 9], [7], [0, 2, 9], [7], [2, 6], [6], [6], [9], [0], [9], [5], [0, 8], [7], [2], [2], [5], [1], [2], [6], [2], [9], [6], [2], [3], [0], [3], [9], [1], [7], [8], [8], [4], [0], [1], [8], [2], [7], [9], [3], [6], [1], [9], [0], [7], [2, 3, 5], [7], [4], [5], [8], [0], [2], [9], [6], [3], [0], [6], [2], [5], [3], [7], [3], [7], [2], [5], [3], [1], [1], [4], [9], [9], [5], [7], [5], [0], [2], [0], [2], [9], [7], [3], [9], [5], [4], [5], [4], [2, 6], [5], [6], [1], [4], [3], [4], [4], [3], [7], [8], [5], [7], [8], [0, 8], [2, 5], [7], [6], [0, 9], [5], [4], [8], [6], [8], [3], [5], [9], [9], [9], [4], [0], [1], [0, 4, 7], [8], [1], [1], [8], [0], [2], [2], [0], [4], [6], [5], [4], [9], [4], [7], [9], [9], [4], [5], [6], [2, 6], [1], [5], [3], [8], [9], [4, 7], [8], [5], [7], [0], [7], [0], [5], [0], [0], [4], [6], [9], [0, 4], [9], [5], [6], [6], [6], [2], [8], [0], [1], [7], [6], [7], [5], [9], [1], [6], [2], [5], [3, 5], [3], [8], [5], [9], [4], [6], [4], [3], [2], [0], [7], [6], [0, 4], [2], [3], [9], [3, 7], [9], [2], [2, 6], [7], [1], [3], [6], [6], [8], [2, 9], [7], [5], [4], [0], [8], [4], [0], [9], [3], [4], [8], [9], [2, 6], [9], [2], [6], [1], [4], [7], [3], [2], [3], [8], [5], [0], [2], [1], [6], [4], [3], [3], [9], [6], [9], [8], [8], [5], [8], [6], [6], [0, 4], [1], [7], [7], [1], [2, 9], [7], [9], [9], [4], [4], [1], [2, 6, 8], [2, 5], [6], [8], [7], [6], [8], [3], [0], [5], [3], [3], [0], [7], [9], [1], [3], [4], [4], [5], [3], [9], [5], [6], [9], [2], [1], [1], [4], [1], [9], [4], [7], [6], [3], [0], [9], [0], [1], [3], [6], [4, 7], [2, 6, 8], [3], [2], [8], [3], [1], [0], [5], [1, 9], [6], [4], [0], [9], [2], [9], [6], [3], [0], [3], [2], [2], [7], [8], [3], [8], [2], [7], [5], [7], [2], [4], [8], [7], [4], [2], [9], [8], [2, 8], [2, 6], [0, 8], [2, 8], [7], [4], [2, 3], [3], [8], [4], [9], [4], [8], [8], [1], [8], [0], [1], [0], [6], [5], [4], [0], [7], [9], [1], [0], [1], [4], [1], [5], [2], [7], [0], [7], [2, 6, 9], [7], [3, 4, 6], [6], [2], [3], [9], [0, 2, 9], [9], [1], [2], [2], [6], [8], [2], [1], [3], [2, 6], [6], [0], [1], [2], [7], [0], [5], [4], [0, 2, 9], [1], [6], [4, 6], [0, 2, 9], [4], [2], [2, 6], [0], [5], [9], [1], [7], [6], [7], [0], [3], [9], [6], [8], [3], [0], [0], [4], [7], [7], [1, 2, 9], [4], [7], [6], [7], [1], [4], [7], [4], [4], [8], [4, 6], [7], [7], [2, 5], [2, 5], [7], [2], [0, 9], [8], [9], [2, 5], [8], [0], [2, 6], [2], [0], [8], [7], [3], [7], [6], [5], [3], [9], [3], [2], [2], [5], [4], [9], [2], [9], [2], [7], [0], [7], [2], [1], [0], [2], [0], [2], [4], [0], [9], [8], [1], [0], [7], [7], [0], [7], [8], [4, 7], [6], [3], [3], [0], [1], [3], [7], [0], [1], [3], [1], [4], [2], [3], [8], [4], [2], [3], [7], [8], [4], [0], [0], [1, 9], [0], [0, 9], [1], [1], [4], [4], [6], [7], [3], [1], [1], [3], [7], [3], [5], [2, 5], [6], [6], [5], [8], [7], [1], [6], [8], [8], [4], [3], [2, 6], [4], [0], [1], [4], [8], [8], [0], [6], [9], [9], [2, 9], [5], [3], [2, 6, 8], [6], [0], [0], [4], [2], [3], [2, 3], [7], [2], [2], [5], [9], [8], [9], [1], [7], [4, 6], [0], [3], [0], [1], [3], [8], [3], [9], [6], [1], [4], [7], [0], [2, 5], [7], [8], [9], [1], [1], [6], [6], [2, 6], [2, 3], [9], [1], [9], [9], [4], [2, 6], [1], [7], [0], [6], [8], [1], [9], [2], [9], [7], [4], [7], [8], [3], [1], [2], [0], [1], [5], [8], [3, 7], [2, 9], [3], [8], [1], [3], [8], [5], [0], [8], [4], [8], [1], [1], [8], [9], [6], [0], [8], [2, 6], [1], [3], [4], [1], [6], [0], [3, 7], [1], [1], [0], [0], [3], [5], [2, 6, 9], [0], [6], [6], [3], [0, 4], [6], [3], [3], [2, 6], [0, 4], [7], [2], [2], [2], [5], [5], [0], [8], [5], [2, 9], [1], [1], [1], [0, 3], [2, 9], [0], [3], [1], [5], [3], [7], [2, 6, 9], [8], [9], [1], [6], [4], [9], [3], [9], [0], [9], [6], [3], [2, 6], [8], [7], [2, 3], [8], [0, 8], [0], [0], [2, 6], [6], [6], [9], [2], [5], [4], [4], [6], [3], [6], [0], [8], [6], [0, 4], [2, 6], [2, 6], [7], [5], [1], [2], [4], [8], [8], [0], [9], [4], [9], [7], [2], [0], [2], [8], [4], [8], [9], [1], [5], [5], [7], [7], [5], [3], [8], [3], [3], [6], [0], [8], [4], [6], [7], [9], [2], [4], [1], [6], [9], [0, 9], [2, 3, 9], [8], [6], [1], [8], [6], [1], [4], [2], [9], [2], [7], [4, 6], [2, 6], [0], [8], [6], [9], [1], [7], [1], [8], [8], [0], [7], [5], [8], [0], [3], [3], [3], [7], [7], [9], [0, 4, 7], [3], [1], [9], [1], [9], [2, 6], [3], [3], [2], [1], [0], [3], [1], [4], [1], [0], [0], [1], [1], [6], [2, 3, 5], [4], [6], [2], [0], [7], [9], [8], [7], [2], [0], [6], [0, 8], [1], [4], [3], [7], [0], [2, 6], [1], [8], [5], [7], [8], [4], [8], [3], [2, 9], [9], [9], [8], [2, 4, 5, 7], [6], [6], [3], [2, 3], [1], [3], [9], [1], [4], [1], [5], [2, 5], [0], [1], [3], [2], [0, 8], [8], [8], [2, 5], [2, 6], [7], [2], [2], [4], [7], [2], [5], [8], [2], [4], [9], [2], [1], [8], [1], [9], [8], [8], [8], [1], [0], [4], [3], [3], [1], [8], [4, 7], [6], [3], [3], [2, 5], [2, 3], [2], [8], [5], [8], [9], [5], [8], [0, 9], [8], [9], [1], [2, 6, 9], [5], [9], [4], [4], [8], [0], [7], [2], [9], [0], [4], [1], [6], [4], [0, 4], [9], [1], [2], [5], [2, 6], [0], [2, 8], [6], [1], [9], [4], [5], [9], [5], [0], [7], [2], [0], [9], [4], [4], [6], [6], [5], [5], [2], [8], [1], [7], [2], [1], [4], [3], [6], [3, 7], [1], [0, 4], [7], [0], [9], [4], [3], [8], [2], [8], [4], [7], [2], [3], [1], [3], [2], [9], [8], [9], [7], [9], [5], [1], [4], [0], [8], [2, 9], [3], [8], [9], [1], [1], [3], [2], [4], [9], [3], [1], [7], [4], [6], [2], [8], [9], [5], [3], [9], [5], [5], [6], [7], [2], [4], [5], [3], [1], [2], [0], [0], [5], [4], [7], [6], [1], [1], [9], [8], [1], [0], [1], [3], [1], [1], [1], [7], [3], [9], [6], [8], [4], [6], [0, 8], [4], [9], [4], [7], [9], [7], [2, 6], [8], [4], [9], [4, 7], [0], [1], [6], [1], [5], [1, 9], [0], [4], [3], [4, 6], [1], [4], [0], [8], [4], [6], [2], [2], [6], [5], [3], [6], [7], [1], [1], [8], [2, 6], [0], [4], [0], [1], [9], [7], [1], [3], [5], [5], [8], [4, 7], [7], [3], [9], [7], [7], [7], [0, 2, 9], [1], [2], [8], [6], [4], [0], [7], [9], [8], [2], [8], [0, 4], [1], [1], [2, 9], [0, 2, 9], [0, 3], [8], [5], [8], [1], [3], [2], [3], [1], [2], [7], [2, 9], [8], [1], [8], [1], [8], [6], [0], [2], [4], [1], [3], [6], [7], [4], [4], [4], [3], [3], [4], [3], [2], [4], [3], [7], [8], [4], [4], [4], [2, 5], [4], [2], [2], [8], [4], [5], [5], [4], [1], [4], [2], [3], [9], [6], [4], [3], [4], [4], [0], [8], [8], [4], [5], [7], [5], [6], [9], [1], [6], [7], [2], [0], [1], [4, 7], [5], [6], [0, 9], [0], [2], [3], [3], [6], [0], [2, 6], [2, 3, 8], [9], [1], [4, 7], [7], [5], [2], [5], [6], [4], [1], [4], [3], [3], [3], [0], [3], [5], [5], [8], [9], [7], [3], [1], [3], [2, 4, 5], [3], [4], [4], [3], [3], [3], [1, 8], [1], [7], [7], [0], [2, 5, 7], [4], [5], [1], [4, 7], [2], [4], [3], [0, 9], [9], [4], [9], [9], [1], [8], [1], [6], [7], [2, 5], [5], [4], [9], [7], [6], [5], [9], [2, 6], [4], [0], [7], [8], [5], [5], [0], [0], [9], [9], [8], [0, 4], [5], [4], [8], [3], [6], [3], [6], [0], [2, 6], [6], [6], [9], [6], [4], [8], [6], [2], [4], [5], [8], [1], [2], [7], [6], [5], [7], [0, 8], [1, 8], [2], [0], [8], [6], [9], [0], [8], [9], [4], [0], [9], [0, 4, 7], [9], [5], [7], [5], [5], [9], [5], [3], [0], [1], [9], [3, 7], [2], [4], [1], [0], [1, 8], [0, 2], [4, 5], [1], [7], [8], [0], [4], [4, 7], [2, 6], [3], [4], [0], [0], [9], [0], [8], [4], [3], [1, 9], [3], [9], [0], [5], [2, 9], [5], [0], [1], [4], [8], [1], [0], [5], [2], [1], [0], [2], [8], [1], [5], [6], [7], [7], [5], [3], [2], [5], [0], [1], [4], [2], [5], [2], [3], [2, 6], [2], [1], [7], [2], [9], [5], [5], [3], [0], [4], [8], [5], [7], [6], [3], [8], [1], [0], [1], [3], [3], [0], [7], [2, 6], [9], [5], [3], [2, 6, 8], [0], [1], [4], [4], [4], [4], [2], [2, 5], [0, 4, 5, 7], [8], [1], [5], [9], [8], [1], [1], [7], [3], [1], [9], [3, 7], [6], [5], [0], [8], [4], [2, 9], [0], [9], [2], [8], [4], [4, 7, 8], [1], [2, 5], [9], [2, 6], [8], [9], [0], [4], [6, 9], [2, 6, 8], [7], [8], [1], [4], [8], [9], [4], [2], [5], [3], [7], [9], [0], [2, 9], [9], [5], [5], [8], [5], [0, 4, 7], [2], [8], [3], [4], [2], [7], [7], [8], [6], [7], [8], [2], [3], [5], [6], [8], [0], [2], [3], [7], [0], [1], [9], [1], [6], [2, 5], [3], [2, 9], [3], [2], [9], [6], [8], [6], [9], [3], [0], [9], [2, 8], [0, 4], [7], [8], [5], [0], [0], [1], [3], [9], [1], [5], [3], [4], [4], [0], [9], [9], [9], [9], [8], [2], [4], [2], [2], [5], [1], [3], [1], [0], [9], [4], [2], [1], [6], [0], [3], [2], [2], [3], [1], [0], [2], [5], [7], [2], [8], [4], [7], [8], [3], [5], [0], [5], [7], [4], [4], [2], [2], [7], [3, 7], [6], [0], [2], [7], [6], [2], [3], [0, 9], [7], [7], [2, 8], [9], [1], [4, 6], [2, 6], [0], [6], [6], [5], [5], [6], [3], [9], [3], [2, 6], [3], [7], [6], [4], [9], [5], [6], [4], [1], [6], [2, 3], [8], [2], [3], [9], [2, 6, 8], [5], [1], [5], [0, 4], [5], [7], [3], [4, 7], [8], [9], [1], [2], [2], [5], [6], [8], [4], [6], [5], [3], [9], [9], [8], [2, 5], [3], [2, 6], [4], [5], [9], [7], [3], [4], [1], [0], [2], [4], [6], [3], [5], [2], [8], [0], [0], [1], [8], [3], [1], [2, 3, 5], [5], [2, 8], [3], [8], [5], [8], [6], [3], [5], [5], [5], [0], [0, 2, 9], [5], [2, 5], [7], [1], [8], [0, 4], [2], [4, 7], [3, 5, 9], [4], [2], [9], [6], [2], [2], [4], [3], [0], [2, 6], [0], [1], [3], [2], [2], [7], [0], [1], [0], [7], [7], [0, 7], [2], [1], [6], [5], [0], [2, 9], [2], [0], [1], [2], [6], [0], [1], [6], [6], [5], [3], [4], [0], [0], [1], [1], [0], [2], [5], [9], [7], [8], [6], [4], [6], [0], [2], [0], [1], [9], [2], [6], [9], [0], [7], [2], [3], [4], [8], [0, 8], [2], [6], [8], [9], [7], [1], [9], [3], [7], [2], [7], [9], [6], [9], [0, 8], [7], [8], [5], [2, 9], [8], [3], [9], [0], [0], [3], [5], [7], [1], [0], [2], [7], [5], [8], [2], [2], [3], [3], [1, 8], [2, 5], [1], [9], [3], [1], [4], [0], [4], [4], [9], [0], [1], [3], [9], [2], [1], [2, 4, 5], [0], [2], [8], [4], [8], [2, 6], [8], [2], [2], [5], [9], [6], [9], [3], [1], [2, 3, 6], [4], [4], [2], [7], [2], [4], [2, 5], [0], [2], [8], [4], [5], [1], [2], [6], [8], [1], [7], [6], [8], [7], [4, 7], [3], [3], [3], [5], [7], [2], [2, 5], [2, 6], [1], [7], [1, 9], [0], [2, 3, 6], [4, 7], [9], [8], [0, 9], [5], [0, 8], [0], [7], [3], [3], [3], [8], [1], [4], [0], [1], [5], [4, 7], [3], [4], [6], [0], [8], [8], [2, 3, 6], [3], [3], [2], [9], [7], [2, 5], [1], [6], [0], [5], [9], [9], [4], [5], [9], [4, 7], [8], [3], [3], [2], [5], [1], [9], [5], [5], [1], [1], [8], [9], [7], [0], [3], [3], [2], [0], [2], [6], [9], [3], [9], [1], [3], [6], [7], [2], [6], [3], [2], [2, 5], [5], [2], [7], [5], [2, 8], [0], [8], [2], [7], [7], [1], [7], [4], [0], [4, 7], [2], [6], [1], [2, 5], [9], [7], [6], [2], [7], [0], [5], [6], [0], [1], [1], [8], [4], [5], [0], [1], [4], [4], [8], [9], [8], [1], [3, 4, 7], [2], [7], [0], [0, 2, 4], [2], [6], [7], [9], [4], [0], [1], [0], [4], [2, 5], [0], [8], [0], [7], [6], [1], [0, 8], [8], [5], [9], [4], [5], [4], [0, 4], [9], [0], [6], [1], [2], [5], [1], [6], [7], [1], [5], [8], [8], [0], [3], [9], [0, 4], [0], [6], [4], [9], [2], [4], [3], [0], [2, 6], [4, 6], [4], [6], [6], [7], [8], [3], [8], [8], [7], [2], [8], [0], [2], [5], [6], [8], [7], [2, 8], [9], [9], [0], [0], [6], [8], [1], [1], [7], [4, 6], [4], [2, 9], [2, 5], [6], [9], [2, 6], [2], [4], [1], [8], [2], [3, 4, 5], [1], [6], [8], [6], [8], [5], [9], [0], [1], [0], [0, 4], [9], [2, 9], [9], [2], [9], [7], [8], [5], [8], [6], [6], [8], [1], [6], [5], [8], [5], [1, 9], [2], [1], [6], [7], [5], [2, 6], [3], [0], [9], [8], [9], [5], [8], [9], [9], [3], [6], [4, 6], [4], [8], [8], [1], [7], [3], [0], [4, 6], [0, 9], [4], [1], [2], [2], [9], [2], [2], [9], [7], [4], [1], [3], [1], [0, 4], [3], [1, 8], [2, 5], [8], [9], [3], [2], [2], [0, 1], [2], [9], [0], [5], [1], [2, 5], [8], [2], [1], [0, 8], [3], [2], [4], [8], [4], [0], [6], [4], [2, 6], [9], [8], [4], [7], [6], [2], [4], [7], [7], [6], [0, 4], [2], [2], [3], [2], [4, 5], [9], [0], [0, 2], [1], [2, 6], [3], [8], [5], [2], [4], [8], [8], [6], [0, 4], [5], [7], [6], [3], [4], [0], [4], [0], [3], [8], [4, 7], [8], [0], [4], [2, 9], [3], [6], [2, 3, 6], [8], [1], [6], [0], [8], [4], [3], [1], [4], [5], [2], [4], [3], [6], [0], [7], [1], [3], [5], [7], [1], [8], [0], [4], [8], [2], [7], [7], [0], [2, 6], [2], [4], [3, 5], [3], [1, 9], [3], [1], [6], [4], [2, 6], [7], [4], [7], [0], [8], [1], [3, 7], [1], [4], [6], [2, 9], [5], [7], [4], [5], [4], [9], [7], [7], [2], [3], [3], [6], [7], [2], [1], [6], [1], [0], [6], [9], [6], [0, 8], [2], [0], [4, 6], [3, 6], [7], [0], [2], [0], [0], [0, 4, 7], [5], [3], [2], [7], [8], [5], [5], [2, 6], [2], [8], [9], [1], [2], [2], [0], [3], [4], [9], [1], [6], [9], [0], [0, 8], [3], [6], [4], [6], [7], [5], [1], [8], [9], [0], [5], [0], [5], [4], [3], [8], [5], [0, 3], [0], [8], [5], [9], [2], [5], [6], [5], [7], [3], [7], [2], [1, 8], [8], [4], [2], [1], [2, 6], [2], [9], [9], [8], [2, 9], [3], [1], [0], [5], [2], [4, 7], [3], [9], [5], [9], [1], [1], [3], [2], [7], [7], [4], [1], [9], [4], [3], [5], [2, 9], [7], [7], [6], [1], [3], [4], [7], [5], [4], [0], [7], [7], [0, 8], [0], [1], [5], [4], [3], [7], [9], [8], [7], [0], [9], [0], [3], [7], [6], [5], [8], [4], [5], [6], [5], [5], [4], [2], [9], [2], [5], [0, 9], [2], [0], [1], [1], [3], [7], [9], [5], [1], [6], [0], [3], [3], [7], [2, 6], [4], [5], [2], [3], [6], [0], [3], [0], [4], [1], [3], [8], [1], [2], [3], [2], [7], [1], [2], [5], [6], [8], [6], [6], [5], [4], [2], [9], [1, 8], [6], [2], [0], [4], [1, 9], [5], [5], [6], [6], [5], [6], [9], [4, 7], [9], [0, 4], [8], [3], [1], [9], [8], [1], [9], [0], [3], [0], [4], [7], [7], [2], [6], [5], [6], [9], [7], [7], [5], [7], [0], [8], [6], [2, 5], [8], [3], [8], [9], [5], [2], [9], [2], [7], [4], [1], [9], [7], [0], [0, 8], [1], [2, 6], [0], [2, 6], [5], [1], [4], [2], [8], [2], [8], [3], [2, 5], [1], [4], [9], [8], [1], [1], [0, 2, 9], [9], [9], [4], [6], [8], [5], [5], [2], [2], [0], [8], [5], [1], [9], [7], [9], [1], [3], [3], [1], [0], [3], [8], [9], [2], [0], [2, 9], [2], [0, 2, 9], [2, 9], [4, 7], [8], [3], [0], [7], [0], [7], [0, 2, 9], [5], [5], [4], [3], [0], [9], [9], [0], [2, 6], [7], [0], [8], [0, 2, 9], [4], [5], [2], [2], [1], [0, 4], [5], [3], [4], [3], [4], [0], [8], [4], [8], [5], [5], [4, 6], [5], [1], [7], [2], [4], [0], [5], [6], [8], [7], [6], [2, 3, 9], [1], [3, 7], [3], [6], [0, 4], [5], [5], [3], [1], [8], [7], [3], [0], [2, 6], [7], [1], [1], [9], [6], [7], [2, 6], [1], [2], [3], [9], [8], [3], [1], [7], [4], [8], [4], [7], [5], [8], [6], [2], [5], [0], [2, 6, 8], [2, 6], [4], [4], [9], [4, 6], [6], [1], [3], [7], [7], [9], [2], [1], [3], [1], [3], [2], [4], [0], [7], [1], [3], [1], [3], [2], [1], [8], [8], [1], [9], [3, 7], [3], [3], [2, 6], [9], [0], [6], [8], [4], [1], [5], [7], [0, 2], [4], [7], [0, 8], [4], [9], [0], [7], [0, 4], [2, 6], [7], [1], [8], [5], [8], [8], [7], [0], [0], [2, 3], [2], [2, 5], [7], [0], [6], [4], [4], [9], [1], [8], [6], [3], [9], [4], [9], [3], [3, 5], [7], [5], [9], [7], [7], [4], [5], [8], [2, 9], [8], [9], [5], [3], [1], [9], [3], [2], [0], [1], [1], [8], [1], [1], [0, 9], [8], [9], [9], [8], [2], [6], [9], [1], [9], [0, 9], [1, 2, 9], [9], [2], [0, 2, 9], [2, 9], [9], [0], [9], [9], [2], [1], [7], [0], [5], [6], [6], [9], [8], [3], [0], [2], [2], [7], [4], [8], [5], [0], [4], [2], [3], [5], [7], [6], [6], [6], [5], [6], [3], [4], [3, 5], [8], [8], [3], [0, 2, 9], [3, 5, 7], [9], [2, 9], [6], [9], [2, 6], [1], [3], [7], [8], [0], [3], [5], [4, 7], [7], [6], [9], [8], [2], [3], [9], [3], [3], [7], [8], [3], [2, 3, 5], [2, 3, 5], [1, 9], [6], [1], [4], [7], [4, 7], [8], [7], [7], [1], [3], [0], [3], [2], [5], [4], [9], [3], [5], [4], [7], [0], [3], [7], [0], [2], [1], [2, 5], [8], [7], [3], [5], [7], [8], [5], [7], [8], [1], [3], [4], [7], [0], [8], [3], [2], [0, 2, 9], [2], [4], [1], [6], [5], [9], [8], [5], [5], [4], [1], [0], [9], [4], [4, 6], [3], [0, 4], [2, 4, 8], [0, 2, 8], [0], [4, 8], [2], [9], [3], [9], [7], [7], [6], [3], [9], [2], [9], [3], [7], [7], [8], [2, 9], [2, 9], [0, 2, 8], [2], [5], [3], [6], [4], [7], [2], [2], [7], [8], [7], [2], [5], [9], [0, 4], [7], [0], [3], [6], [1], [0, 8], [2], [9], [7], [0, 4], [9], [1], [2, 6], [8], [1], [0, 4], [3], [3], [5], [4], [8], [9], [3, 7], [0, 4], [4], [1], [3], [4], [9], [2, 8], [7], [9], [3], [1], [2], [1], [6], [6], [6], [5], [7], [4], [5], [8], [5], [2], [8], [7], [8], [2], [3], [6], [1], [3, 5], [3], [9], [5], [1], [9], [0], [9], [0], [0], [2, 6, 8], [2], [4], [8], [5], [7], [6], [1], [2], [9], [4], [5], [0], [3], [3], [7], [4], [7], [1], [4], [5], [0], [2, 5], [8], [5], [0], [0], [6], [2], [0], [8], [4], [5], [4], [5], [6], [4], [7], [9], [4], [2, 3, 6], [0], [2, 6], [4], [2], [0], [2, 5], [4], [6], [1], [1], [5], [5], [2], [2], [6], [3], [4], [5], [0], [1], [3], [2], [0, 7, 9], [9], [6], [5], [0], [2], [9], [7], [1], [7], [2], [2], [0], [2, 8], [6], [4], [3], [2], [4], [7], [0], [4], [1], [6], [5], [1], [2, 9], [0, 4], [3], [9], [0], [0, 2, 9], [2], [0], [0, 2, 9], [4], [0], [1], [9], [8], [4], [9], [4], [3], [4], [3], [3], [4], [0], [4], [3], [5], [8], [9], [1], [5], [8], [1], [8], [2], [4], [4], [2], [4], [1], [1], [6], [6], [8], [5], [2], [2], [5], [0], [8], [2], [3], [6], [2], [9], [6], [1], [4], [5], [9], [0], [1], [7], [0], [8], [1], [1], [6], [6], [9], [5], [0, 4], [9], [7], [8], [6], [9], [1], [7], [6], [0], [9], [3], [2], [3], [2], [0], [3], [4], [9], [7], [1], [4], [4], [6], [1], [3], [8], [8], [5], [6], [5], [7], [4, 6], [7], [2], [3], [2, 5], [2, 5], [2, 6], [2], [7], [3, 6], [0, 4], [3], [6], [2, 9], [6], [3], [2, 9], [0], [9], [5], [1], [1], [5], [3], [2, 5], [4], [3], [2], [1], [0], [0, 4], [3], [5], [4], [8], [9], [3], [3], [1], [8], [0], [1], [3], [3], [4, 7], [4, 7], [2], [9], [7], [6], [8], [1], [8], [9], [9], [3], [1], [7], [3], [0], [0], [2], [0, 9], [5], [9], [2], [7], [4], [6], [0], [1], [6], [1], [6], [7], [5], [5], [2], [2, 5], [9], [4], [0], [2], [3], [4], [0, 9], [4], [1], [0], [0], [2], [3], [2, 5], [9], [2], [8], [9], [5], [7], [9], [1], [4], [2, 6], [2], [8], [3], [4], [8], [9], [3], [1], [1], [6], [3], [8], [4], [6], [4], [5], [2], [6], [4], [2], [3], [2, 9], [3], [6], [8], [5], [2], [2], [7], [1], [2, 6], [2], [5], [9], [4], [8], [1], [6], [9], [2], [7], [3], [3], [2], [9], [7], [0], [2], [9], [3], [4], [1], [7], [9], [5], [8], [9], [7], [3], [3], [0], [9], [7], [4], [2], [4], [7], [0], [1], [8], [1], [0], [4], [6], [1], [9], [9], [0], [1], [2], [5], [6], [9], [7], [7], [3], [4], [2], [0], [2], [5], [7], [7], [4], [7], [1], [4], [2], [0], [6], [1], [7], [5], [6], [5], [2, 5], [9], [2], [7], [8], [5], [9], [2], [8], [5], [4], [3], [7], [9], [8], [1], [2], [2], [8], [9], [3], [0], [8], [4, 7], [0], [2], [0], [1], [4, 6], [2, 9], [8], [5], [5], [7], [9], [2, 6, 8], [3], [7], [9], [1], [5], [6], [9], [9], [7], [2], [0, 8], [9], [0], [8], [5], [9], [2, 5], [2], [9], [8], [1], [9], [1], [8], [3], [7], [6], [4], [2, 9], [3], [7], [0], [3], [5], [8], [8], [8], [7], [9], [6], [2, 9], [7], [4], [5], [7], [6], [7], [1], [7], [3], [6], [8], [4], [6], [6], [7], [1], [3, 6], [9], [3, 7], [1], [7], [0], [1], [2, 6], [3], [2, 5, 7], [9], [0], [1], [2, 5], [5], [2], [2], [3], [4], [9], [8], [5], [4], [4], [9], [7], [6], [7], [3, 7], [1], [0], [3, 7], [5], [1], [9], [2, 6], [3], [3], [1], [5], [6], [6], [2], [4], [6], [8], [8], [9], [6], [2, 6], [1], [0], [7], [5], [8], [2], [1], [3], [8], [1], [4], [3], [5], [0], [3], [0], [9], [5], [2], [8], [4, 7], [1], [9], [0], [4], [4], [8], [2], [9], [0], [7], [9], [8], [7], [1], [6], [2], [9], [2, 9], [5], [9], [7], [6], [7], [7], [1], [1], [2], [4], [2], [0], [6], [8], [3], [6], [0, 2], [2], [9], [4, 7], [2], [4], [0], [0], [5], [8], [6], [8], [2], [7], [2, 8], [3], [1], [8], [1], [6], [5], [9], [7], [8], [9], [6], [5], [8], [1], [9], [4], [0], [4], [1], [4], [3], [6], [2], [2], [0], [0], [9], [7], [0], [7], [4], [3], [2], [7], [7], [4], [5], [4], [3], [3], [5], [4], [0], [0], [0], [7], [7], [1], [6], [5], [0], [7], [7], [4], [2, 6], [1], [8], [5], [9], [3], [5], [6], [5], [2], [7], [2, 3], [5], [8], [1], [0], [6], [8], [7], [8], [8], [5], [7], [5], [4], [9], [7], [3], [3], [8], [8], [4, 6], [9], [4], [7], [2], [0], [8], [0], [7], [0, 8], [3], [2, 6], [5], [2], [0, 4], [2, 3, 5], [0], [4], [8], [2, 6], [4], [0], [6], [4], [4, 7], [6], [0], [1, 8], [0, 8], [0], [6], [1], [1], [6], [1], [4], [2], [1], [2], [2], [4], [4], [0, 4], [3], [8], [2, 8], [5], [1], [8], [2], [2, 3], [3], [9], [6], [6], [3], [0], [7], [3], [3], [2], [7], [4], [5], [6], [0], [2], [1], [8], [1], [0], [9], [3, 5], [1], [0], [5], [0, 4], [0, 4], [3], [3], [6], [7], [2, 6], [0], [0], [5], [7], [4], [7], [7], [0], [6], [1], [3], [9], [0, 9], [9], [0], [3], [8], [4], [0, 8], [8], [4], [1], [0], [2], [2], [4], [1], [1], [2], [4], [3], [4], [1], [4], [7], [1], [0], [0], [9], [0], [4], [2], [8], [8], [5], [5], [0], [4], [0], [8], [6], [2], [5], [9], [2], [9], [1], [1], [2, 5], [4], [7], [5], [8], [6], [7], [1], [5], [5], [5], [4], [1], [0], [9], [9], [8], [9], [8], [6], [8], [5], [8], [9], [4], [6], [2], [6], [3], [0, 4, 7], [4], [0], [0], [1], [7], [5], [1], [5], [1], [3], [1], [2, 6], [0, 8], [2], [2, 9], [6], [9], [1], [2, 9], [9], [1], [7], [2], [6], [1], [9], [0], [0], [1], [9], [9], [0], [8], [4, 6], [5], [2, 3, 5], [3], [0], [3], [3], [0], [4], [4], [7], [5], [0, 4], [1], [0], [8], [8], [1], [2], [1], [5], [4], [5], [9], [6], [7], [1], [0], [6], [9], [2, 9], [7], [7], [3], [9], [9], [1], [9], [7], [0], [1], [3], [5], [4], [6], [3], [8], [0, 8], [0], [4], [8], [3], [6], [3], [3], [0], [3], [5], [2], [6], [8], [4], [9], [9], [9], [2, 6], [0], [4, 6], [2, 9], [8], [1], [1], [0], [0], [0, 3], [0, 4, 7], [4], [1], [1], [9], [7], [7], [4], [6], [8], [6], [0], [2], [8], [5], [2], [5], [3], [5], [7], [9], [8], [4], [4], [3], [1], [4], [8], [4], [2, 6], [5], [3], [8], [8], [9], [5], [7], [6], [2], [0], [0, 4], [9], [9], [0], [5], [2], [3], [2, 6], [1], [1], [0], [2], [8], [2], [1], [1], [7], [5], [2], [3], [4], [1], [2], [9], [2], [1], [0, 2, 9], [4], [8], [9], [0], [0], [4], [1], [0], [2], [2], [0], [6], [8], [7], [3], [3], [8], [9], [0], [2, 5], [0], [3], [6], [1], [3], [9], [5], [0], [5], [4], [4], [0, 8], [1], [0, 3], [2], [1], [7], [9], [9], [2, 6], [2], [4], [3, 7], [1, 8], [3], [4], [7], [0], [2, 5], [8], [2], [8], [5], [8], [8], [8], [3], [3], [7], [7], [3], [0], [4], [1], [5], [9], [7], [0], [2, 6], [8], [4], [9], [0], [1], [8], [9], [6], [3], [9], [2], [4], [4], [0], [5], [3], [3, 4, 7], [4], [5], [1], [1], [8], [2], [2], [9], [3], [7], [8], [9], [2], [3], [1], [7], [3], [0], [2, 4, 5], [0, 4], [1], [9], [5], [5], [3], [4], [3], [2, 6, 8], [0], [0], [3], [1], [3], [4], [7], [4], [2], [8], [4], [8], [9], [9], [4], [2], [4], [3], [2, 6], [4], [6], [4], [6], [6], [3, 7], [8], [7], [4], [8], [0, 2, 9], [5], [9], [3], [0, 2, 9], [0], [7], [5], [1], [9], [7], [9], [1], [1], [4], [2], [1], [6], [4], [3], [3], [1], [4], [9], [6], [1], [5], [1], [5], [4], [4], [3], [3], [9], [7], [8], [2], [5], [4], [4], [5], [4], [2, 5], [7], [2], [5], [3], [1], [5], [7], [8], [3], [6], [0], [2], [5], [2], [2, 5], [7], [4], [2], [1], [6], [8], [6], [8], [3], [2], [7], [7], [9], [7], [1], [4], [7], [3], [2, 6], [1], [5], [3], [0], [0], [6], [6], [8], [6], [6], [0], [3], [4], [7], [4], [1, 8], [4, 7], [9], [9], [3], [4], [1], [4], [0, 8], [3], [7], [1], [2], [2], [0, 8], [4], [7], [8], [5], [5], [6], [5], [6], [0], [6], [4], [9], [4], [2], [7], [3], [8], [3], [9], [4], [1], [6], [9], [9], [4], [3], [9], [0, 8], [1], [6], [9], [5], [1], [0], [9], [7], [2, 5], [2, 5], [4], [2, 6], [6], [4], [8], [1], [9], [5], [6], [3], [1], [8], [6], [0], [7], [6], [5], [0, 2, 9], [3], [2, 9], [6], [1], [2, 9], [2], [1], [2, 6], [4], [9], [0], [4, 7, 8], [9], [1], [0], [5], [3], [1], [6], [9], [8], [9], [0], [6], [1], [6], [2], [3], [5], [6], [1], [0], [7], [2], [4], [0, 8], [3], [2, 6, 8], [8], [6], [9], [1], [2, 9], [0], [2, 6, 9], [2], [3], [9], [5], [0, 4, 7], [1], [9], [2], [0], [7], [3], [5], [1], [8], [2, 3], [0], [5], [2], [9], [8], [0], [9], [6], [0], [3], [5], [3], [4], [1], [3], [0], [7], [3], [9], [4], [5], [3], [1], [4], [2, 6], [4], [9], [9], [7], [1], [7], [0], [1], [2], [1], [5], [3], [2, 6, 8], [4], [1], [3], [1], [9], [9], [7], [0], [1], [7], [6], [2], [6], [5], [0], [0, 3], [1], [0], [8], [9], [9], [0], [8], [8], [7], [9], [2], [9], [1], [3], [6], [7], [6], [0], [8], [6], [2], [4], [2], [3], [5], [5], [4], [1], [6], [4], [1], [2, 6], [1], [7], [1], [2, 6], [2], [3], [0], [4], [2, 6], [9], [7], [3], [5], [6], [0], [0, 2, 9], [8], [1], [1], [3], [5], [2, 6], [3], [3], [8], [7], [2, 5], [0, 9], [7], [7], [5], [7], [1], [9], [9], [1], [1], [9], [3], [5], [3], [3], [0], [9], [0], [6], [6], [2, 5], [6], [8], [9], [4], [2, 5], [1], [1], [2], [2, 6], [9], [0], [1], [2], [5], [4], [4], [7], [4], [8], [3], [2], [4, 7], [4], [5], [7], [0], [1], [2], [9], [2, 6, 8], [1], [5, 7], [3], [5], [9], [1], [9], [1], [9], [3, 7], [6], [7], [4], [0, 8], [3], [2, 5], [6], [7], [0], [1], [7], [7], [3], [2, 5], [3], [2, 5], [1], [7], [6], [0, 8], [4], [4], [5], [4, 7], [3], [4], [7], [7], [3], [6], [0, 2, 9], [7], [2], [6], [7], [4], [1], [8], [0], [2], [2, 6], [1], [5], [4], [0], [9], [3], [0, 8], [4], [2], [3], [8], [5], [0], [0], [4], [6], [3], [9], [2], [0], [5], [7], [5], [5], [1], [7], [3], [1], [2, 6], [7], [9], [0], [1], [2], [1], [4], [6], [1], [5], [9], [5], [0], [4], [9], [4], [9], [7], [1], [2, 6], [8], [0], [6], [5], [2], [8], [1], [7], [5], [6], [9], [3, 8], [2], [3], [9], [8], [6], [1], [0, 2, 9], [9], [0, 8], [9], [8], [7], [7], [2], [2, 5], [3], [5], [3, 5], [7], [2, 8], [7], [2, 5], [9], [1], [9], [8], [6], [5], [6], [7], [0, 3, 7], [6], [7], [2], [0], [9], [6], [6], [7], [0], [1], [0, 4], [1], [3], [4, 6], [8], [6], [1], [2], [2, 5], [1], [9], [9], [8], [6], [8], [3], [8], [9], [2, 5], [4], [0], [3], [3], [6], [4], [0, 2, 9], [9], [7], [0, 4], [3], [5], [2, 6], [4], [6], [0], [3], [3], [5], [0], [2, 6], [0], [2], [7], [2], [9], [2], [4], [0], [2, 6], [6], [3], [4], [5], [5], [9], [1], [9], [4], [2, 5], [3], [5], [4], [8], [0], [0], [3], [9], [2], [7], [4, 7], [2], [8], [3], [6], [3], [1], [9], [6], [3], [0, 8], [3], [3], [4], [7], [2, 5], [0, 4, 7], [7], [2], [1], [2], [6], [1], [5], [2, 9], [0], [7], [5], [0], [0], [0], [1], [2, 6], [3], [3], [8], [4], [3], [1], [7], [1, 6, 9], [0], [4], [0], [4], [1], [4], [0], [1], [2], [1], [7], [7], [9], [8], [7], [5], [4, 7], [0], [9], [0], [0], [8], [2], [0], [0], [2, 9], [0, 4], [8], [6], [2], [4, 7], [6], [3], [5], [1], [3], [0, 2, 9], [7], [2], [2], [9], [8], [0], [0], [0], [3], [4], [4], [6], [1], [6], [4, 7], [4], [4], [2, 5], [9], [4], [0], [8], [0], [4], [6], [2, 5], [7], [9], [7], [0], [5], [7], [7], [3], [1], [9], [2, 5], [2], [9], [5], [3], [7], [9], [4], [4, 7], [9], [7], [7], [1], [4, 7], [1], [4, 7], [8], [7], [4], [0], [4], [7], [2], [9], [7], [6], [9], [3], [5], [1, 8], [0], [3, 7], [6], [8], [3], [2], [4], [7], [1], [1], [3], [9], [7], [0, 2], [1], [0, 2, 8], [8], [7], [0], [1], [6], [9], [3], [2], [7], [7], [8], [1], [0], [3], [2, 5], [6], [7], [3, 5], [2], [0], [1], [5], [2, 5], [1], [4], [1], [3], [0], [8], [2, 6], [2, 5], [1], [4, 6], [6], [4, 7], [1], [9], [0], [4], [1], [0], [1], [9], [0, 8], [6], [9], [2], [4], [7], [2], [0], [7], [4, 7], [9], [1], [2, 5], [2, 6], [6], [3], [4, 6], [4], [1], [4, 7], [8], [2], [6], [6], [1], [6], [5], [6], [3], [8], [4], [6], [7], [1], [9], [5], [6], [4, 7], [6], [0], [7], [1], [9], [3], [2], [4, 6], [7], [7], [6], [5], [9], [1], [5], [6], [0], [2], [2], [9], [1], [8], [4, 6], [3], [3], [0], [0], [5], [7], [7], [2, 8], [5], [3], [5], [1], [6], [1], [3], [1], [0], [6], [2], [3], [2], [1], [3, 7], [5], [1], [9], [8], [3], [4], [9], [7], [3], [0], [2], [6], [9], [4], [4], [3], [9], [6], [8], [6], [6], [8], [2, 5], [4], [5], [6], [7], [7], [4], [6], [9], [6], [2], [4], [0], [1], [3], [6], [4], [9], [2], [2, 6], [0], [3, 7], [8], [7], [5], [3], [3], [8], [2, 5], [2, 9], [6], [3], [6], [2, 5], [7], [4], [5], [7], [9], [0], [0, 4], [6], [7], [0, 2, 9], [0], [3], [5], [7], [5], [5], [2, 9], [4], [6], [4], [2, 5], [3], [5], [6], [4], [1], [6], [3], [1], [6], [7], [0], [5], [0, 2], [1], [9], [7], [3], [5], [2], [3], [2, 9], [5], [6], [2], [0], [0], [0], [0, 8], [0], [3], [2], [4, 6], [5], [3], [7], [9], [6], [9], [3], [1], [2], [2], [7], [4], [5], [1], [3], [7], [2, 6], [9], [5], [8], [5], [8], [5], [8], [5], [6], [5], [0], [8], [6], [1, 8], [1], [8], [1], [5], [0], [9], [0, 8], [6], [3], [6], [2, 5], [4], [5], [7], [4, 7], [7], [4], [3], [2, 3], [4], [4], [5], [7], [5], [0, 4], [5], [8], [0], [5], [4], [0], [5], [4], [3], [2], [2], [0, 4], [2, 5], [9], [4], [8], [8], [6], [0], [6], [1], [7], [0], [4], [3], [8], [5], [9], [7], [4, 6], [4], [1], [0], [2], [3], [5], [6], [7], [1], [6], [2, 9], [8], [3], [5], [2], [5], [7], [5], [7], [7], [1], [7], [4], [0], [3], [4], [0], [4], [2], [7], [0], [2, 5], [2], [6], [6], [2, 9], [5], [2, 6], [6], [0], [6], [1], [5], [9], [0], [0], [1], [3], [5], [1], [6], [7], [8], [4, 8], [6], [3], [3], [6], [0], [9], [9], [2], [2], [6], [1], [4], [6], [2], [5], [7], [8], [8], [3], [6], [3], [0], [2], [3], [4], [4], [4], [8], [9], [2], [6], [0], [9], [7], [9], [8], [7], [7], [3], [8], [2], [9], [3], [0, 3, 4, 7], [7], [5], [8], [7], [3], [7], [0, 4], [7], [1], [6], [2], [4, 7], [3], [0], [2], [9], [1], [2], [8], [0, 4], [4], [5], [2, 5], [0], [1], [2], [9], [6], [1], [0], [1], [0, 8], [6], [5], [0], [5], [7], [4], [0, 4], [8], [3], [5], [3], [7], [2], [5, 7], [8], [3], [5], [7], [3], [4, 7], [0], [5], [4], [5], [2, 6], [9], [3], [5], [4], [8], [2], [4], [2], [2, 9], [4, 6], [7], [6], [0], [5], [5], [8], [4, 7], [5], [6], [1], [3], [5], [4], [7], [3], [0], [7], [2], [8], [1], [2], [4], [9], [6], [4], [5], [9], [7], [4, 7], [2], [7], [4], [3], [1], [6], [9], [4], [8], [0], [5], [9], [4, 6], [4], [4], [3], [1], [4], [6], [3], [0], [8], [9], [7], [6], [9], [4], [2, 6, 8], [1], [2], [5], [9], [0, 4], [7], [1], [4], [5], [0, 4], [1, 9], [3], [6], [4], [7], [1], [5], [9], [4], [1], [0, 4], [2, 8], [7], [7], [0], [0, 4], [5], [4], [6], [7], [7], [2, 5], [4], [4], [4], [3], [6], [6], [1], [9], [9], [7], [9], [4], [3], [2], [9], [8], [5], [0], [6], [9], [0], [9], [7], [8], [5], [4], [4], [9], [4], [2, 6], [6], [6], [9], [9], [7], [9], [9], [0], [5], [1], [1], [0, 8], [6], [9], [9], [5], [6], [5], [5], [9], [7], [9], [4], [5], [4], [3], [3], [9], [8], [0, 8], [5], [7], [8], [4, 7], [0], [2], [0], [7], [2], [8], [0, 9], [2], [0], [7], [4], [0], [6], [2], [3], [1, 9], [4, 7], [4], [6], [3], [0], [4], [9], [5], [6], [6], [3], [0], [3, 5], [2], [4, 6], [3], [3], [0], [0], [8], [5], [4], [2], [9], [5], [0], [5], [4], [1, 8], [2], [1, 8], [6], [2], [7], [8], [2], [0], [1], [8], [2], [4], [8], [4], [3], [0], [4], [0], [1], [9], [3], [0], [3], [4, 6], [5], [5], [2], [8], [3], [0], [9], [4], [5], [2], [4], [3], [7], [0], [2], [3], [1], [0], [0], [6], [1], [2], [1], [4], [2, 6], [7], [1], [0], [5], [2], [5], [9], [2, 9], [5], [6], [7], [1], [9], [3], [6], [1], [0], [2], [9], [4], [2], [9], [4], [8], [2], [9], [8], [5], [1], [0], [1], [5], [2], [5], [6], [8], [0, 8], [3], [2, 5], [0], [0, 4], [1], [3], [7], [0], [3], [4], [9], [2], [3], [9], [9], [8], [5], [9], [5], [5], [1, 2, 3, 9], [9], [4], [7], [1], [3], [6], [4, 7], [4], [8], [9], [0], [7], [1], [2], [4], [2, 9], [3], [7], [5], [1], [1, 8], [3], [5], [2], [4], [1], [1], [5], [3], [9], [2], [5], [0, 8], [8], [8], [1], [5], [1], [5], [9], [0], [9], [2], [4], [0], [6], [9], [1], [1], [3], [3], [9], [5], [3], [3], [2, 6], [3], [4], [1], [2, 3], [9], [8], [7], [2, 5], [8], [7], [3], [5], [2], [5], [2, 8], [2, 9], [7], [2], [0], [0], [7], [5], [3], [5], [7], [4, 7], [6], [2], [8], [2, 6], [7], [2, 6], [6], [1], [3], [8], [6], [2, 9], [0], [4], [2, 4], [8], [2], [4], [0], [2, 9], [5], [4], [1], [2], [4], [4], [6], [9], [2], [0], [5], [2], [2], [8], [2], [4, 6], [4], [7], [9], [5], [7], [2], [2, 6], [2], [1], [9], [9], [7], [2], [5], [1], [2, 8], [1], [6], [3], [0], [8], [8], [5], [6], [9], [9], [9], [6], [3], [0], [8], [8], [5], [3], [4], [1], [1], [0], [7], [0], [4, 6], [0], [4], [4], [2, 6], [5], [3], [2], [9], [6], [6], [7], [9], [7], [7], [0, 4], [8], [4], [2], [7], [7], [7], [4], [0], [1, 8], [6], [0], [5], [3], [2], [2], [4], [9], [7], [3, 6], [3], [2], [8], [8], [5], [3], [8], [0], [8], [0], [0], [0], [2], [2], [7], [0], [7], [7], [7], [2], [2], [0], [4], [0], [2], [7], [8], [4], [7], [9], [6], [9], [1], [6], [9], [3], [8], [9], [5], [1, 8], [3], [1, 9], [4, 5], [3], [7], [5], [5], [2, 9], [3, 7], [5], [7], [9], [6], [3], [0, 8], [8], [4, 6], [5], [6], [1], [0, 8], [7], [8], [4], [7], [1], [3], [2], [0], [9], [1], [8], [9], [6], [8], [1], [7], [1], [0], [1], [7], [6], [4], [4], [8], [2], [1], [2], [6], [8], [1], [1], [8], [8], [8], [9], [0], [0], [5], [3], [3], [5], [6], [2, 6], [3], [1], [4], [4], [7], [8], [0], [1], [2, 6], [8], [4], [6], [2], [2], [2, 9], [6], [3], [4], [0], [8], [1], [3], [2, 8], [3], [8], [1, 8], [1], [6], [1], [9], [8], [2], [0], [4], [7], [4], [0], [2], [7], [6], [8], [9], [1], [6], [2], [8], [8], [4], [1], [1], [0], [7], [0, 4], [2], [4, 6], [7], [7], [2], [6], [6], [7], [4], [5], [2, 3, 8], [0], [9], [2, 5], [7], [2], [5], [2, 6], [2], [2], [3, 7], [6], [2, 6], [6], [4], [1], [4, 6], [8], [3], [8], [5], [5], [2], [3], [4], [5], [0, 4], [7], [2, 3, 5], [1], [5], [3], [7], [8], [8], [9], [0, 2, 9], [0], [8], [2], [6], [0], [0, 8], [1], [4], [1], [3], [5], [1], [2, 6, 8], [9], [6], [4], [6], [9], [5], [6], [5], [9], [1], [4], [2], [8], [9], [5], [4], [7], [0, 3, 8], [3], [7], [1], [6], [9], [1], [1, 9], [4], [0], [5], [1], [6], [3], [8], [2], [5], [2, 5], [5], [2], [8], [2, 9], [2, 3, 6], [1], [6], [2, 6], [7], [0], [8], [9], [2], [6], [4], [7], [5], [5], [8], [8], [7], [8], [5], [7], [4], [4], [0], [0], [7], [0], [4], [0], [4], [4], [2], [3], [4], [0], [7], [0, 4, 7], [7], [0], [4], [6], [2], [0, 2, 7, 9], [1], [1], [5], [0, 8], [9], [1], [0], [6], [5], [3], [0], [9], [0], [6], [2], [2], [4], [1], [6], [7], [6], [1], [0], [4], [6], [0], [4], [4], [2], [7], [6], [4], [3], [5], [9], [4, 6], [5], [2], [0], [5], [7], [2], [3], [9], [4], [5], [0, 8], [1], [9], [3], [1, 9], [8], [5], [8], [6], [6], [3], [4], [0], [3], [3], [2], [6], [1], [8], [2], [1], [5], [6], [3], [2], [3], [3], [5], [0], [2], [1], [2], [8], [0], [8], [2], [2], [7], [3], [7], [9], [8], [3], [6], [1], [0, 2, 9], [8], [6], [7], [5], [8], [9], [4], [8], [0], [0], [2], [0, 9], [1], [8], [3], [7], [2], [8], [0, 4], [9], [3], [8], [9], [2, 6], [8], [9], [5], [4], [8], [9], [5], [5], [7], [2], [5], [8], [2, 8], [1], [2], [3], [1], [5], [0, 9], [2], [3], [0], [8], [2], [2], [8], [7], [3], [5], [2, 6], [9], [6], [3], [5], [1], [1], [7], [7], [2, 9], [3], [8], [0, 2, 9], [6], [0], [8], [0], [3], [6], [4], [6], [9], [1], [1], [7], [0], [6], [2, 8], [9], [0, 9], [6], [1], [0], [1], [1], [7], [2], [1], [0], [4], [5], [0], [3], [6], [3], [3], [8], [1], [8], [1], [6], [1], [3, 5], [4], [5], [1], [8], [9], [9], [3], [1], [7], [0, 2], [9], [8], [9], [4], [6], [0], [9], [4], [0], [4], [4, 6], [2], [1], [1], [0], [8], [5], [6], [0], [3], [4], [6], [9], [0, 3, 4], [7], [9], [0], [3], [6], [5], [3], [8], [5], [1], [2], [2], [9], [7], [0], [0], [1], [4], [4], [5], [5], [9], [6], [3], [6], [2], [6], [9], [3], [3], [3], [2, 9], [4, 5], [9], [2, 5], [2], [1], [6], [6], [4], [7], [6], [3], [4, 6], [8], [1], [4], [6], [4], [4], [5], [6], [2, 5], [0], [5], [2], [3], [5], [2], [5], [2], [5], [9], [0], [2, 6], [7], [9], [8], [5], [2], [1], [4], [2, 5], [4], [5], [5], [6], [8], [6], [0], [0], [9], [2], [0], [7], [7], [6], [2], [0, 3, 7], [5], [9], [8], [5], [9], [5], [3], [0, 4], [4], [0, 8], [2, 6], [3], [9], [1], [3], [9], [8], [3], [7], [4], [4], [0, 8], [2], [1], [9], [1], [2], [6], [8], [4], [7], [3], [1], [4], [3], [3], [1], [0], [8], [8], [8], [8], [1], [4], [7], [3], [1, 8], [6], [9], [1], [6], [0], [7], [7], [1], [3], [3], [3], [1], [0], [2], [7], [1], [2], [2], [1, 9], [6], [3], [5], [9], [4], [8], [0], [4], [0, 8], [0], [1, 9], [2, 3], [5, 7], [2], [4], [0, 4], [0], [8], [6], [4], [3], [9], [2, 8], [2], [2], [8], [3], [1], [1], [2], [8], [2], [6], [9], [6], [8], [0, 3, 7], [4], [1], [5], [2], [6], [9], [0], [0], [7], [1], [8], [9], [3], [9], [9], [0], [7], [7], [3], [4], [2], [6], [4], [5], [7], [7], [8], [7], [2], [6], [2], [2], [4], [4], [0], [7], [1], [2, 5], [9], [6], [0], [0], [3], [0, 3], [8], [0, 4], [2], [4], [3], [5], [0], [9], [1], [0], [0], [6], [5], [0], [7], [9], [9], [6], [5], [5], [8], [2, 5], [7], [1], [6], [2, 6], [4], [1], [2], [4], [1], [5], [0], [0], [4], [3, 5], [8], [2], [8], [3], [0], [2, 5], [0], [5], [7], [1], [6], [7], [0, 8], [9], [1], [5], [7], [6], [5], [5], [3, 7], [6], [0], [0], [1], [7], [3], [1], [9], [2], [4], [1], [3, 6], [7], [8], [0], [0, 8], [9], [6], [2, 6, 9], [0], [2, 6], [2, 6], [8], [2], [7], [7], [0], [2], [7], [7], [8], [8], [7], [0, 2, 9], [3], [9], [1], [4], [4], [5], [2, 4, 5], [4], [6], [2], [3], [1], [0], [3], [3], [3], [6], [5], [1], [2], [8], [0, 9], [7], [9], [3], [8], [7], [3, 4], [1], [7], [7], [3], [2], [2], [0, 8], [9], [5], [9], [2], [1], [7], [4], [4], [0], [5], [0, 7], [1], [5], [4], [2], [8], [4], [9], [8], [7], [8], [0, 4], [2], [3], [4], [0], [5], [4], [1], [8], [2], [5], [4], [5], [2], [5], [3], [7], [9], [5], [1], [0, 4, 5], [9], [3], [1], [4], [5], [5], [1], [7], [1], [7], [0], [1], [9], [5], [7], [0], [6], [3], [5], [7], [5], [5], [8], [9], [4], [6], [3], [6], [6], [8], [2], [6], [4], [8], [4], [1], [3], [9], [2], [3], [2, 3, 5], [0], [1], [6], [0, 4], [2], [8], [2], [4], [4], [1], [4], [4], [4], [4], [1], [5], [5], [0], [2, 6], [5], [4], [5], [6], [5], [6], [2], [4], [7], [2, 9], [4], [6], [5], [0], [2], [3], [9], [2], [3], [8], [0], [7], [0], [6], [8], [1], [2], [8], [9], [1], [5], [4], [2], [3], [5], [5], [2, 6, 8], [2, 6], [5], [0], [3], [2, 5, 7], [1], [3], [3], [7], [7], [4], [9], [4], [5], [9], [5], [1], [7], [6], [6], [2], [8], [5], [1], [2, 5], [8], [4, 6], [3], [3], [5], [3], [0, 9], [4], [8], [7], [2, 9], [9], [2, 3, 5], [8], [4], [4], [9], [1], [0], [3], [1, 8], [3], [8], [0], [5], [5], [4], [2], [9], [2], [7], [2], [0], [7], [2, 6], [9], [7], [5], [0], [7], [0], [3], [5], [3], [3], [8], [7], [7], [1], [6], [2, 9], [8], [9], [0], [1], [1, 9], [4], [0], [0], [1], [7], [2], [2, 5], [8], [5], [9], [1], [2], [8], [0], [6], [6], [8], [6], [9], [2, 5], [1], [1], [5], [3], [5], [0], [7], [6], [1], [4], [4], [1], [1], [8], [1], [1], [2], [3], [4], [9], [9], [3, 5], [2], [7], [2], [3], [6], [1], [2, 6], [9], [8], [8], [6], [7], [4], [7], [2], [3], [8], [0], [9], [0, 9], [7], [8], [1], [2], [3], [0, 2], [2], [2], [9], [0], [4, 7, 8], [8], [9], [6], [5], [5], [2], [4], [1], [0, 9], [6], [1], [1, 8], [4], [5], [6], [5], [0], [8], [9], [0], [5], [7], [9], [6], [5], [4], [6], [4], [9], [3], [1], [0], [5], [2], [1], [0], [3], [2], [9], [8], [1], [9], [7], [7], [3], [1], [4], [1], [9], [3], [2, 8], [8], [1], [9], [3], [8], [9], [5], [1], [1], [6], [2, 9], [7], [2], [6], [4], [6], [9], [6], [0], [1], [2, 3, 5], [9], [3, 7], [8], [2, 8], [0, 8], [2], [9], [1], [6], [6], [0], [5], [0], [7], [4], [7], [9], [4], [5], [0], [0], [3], [5], [3], [8], [9], [1], [2], [7], [1], [3], [3], [6], [9], [1], [0], [7], [1], [9], [5], [8], [1], [9], [1], [7], [9], [1, 8], [5], [0], [2, 9], [6], [9], [2], [2], [4], [0], [8], [4], [8], [1], [7], [7], [2], [7], [9], [5], [2], [2], [9], [2], [6], [5], [7], [2], [5], [6], [5], [1], [8], [2], [6], [8], [6], [5], [0], [8], [0], [0], [9], [2, 9], [2], [8], [0, 8], [6], [6], [0], [7], [9], [8], [0], [5], [0], [9], [6], [0], [4], [7], [1], [7], [8], [8], [2], [3], [9], [3], [5], [5], [3], [1], [5], [3], [0], [2], [5], [2], [7], [3], [8], [4], [4], [6], [1], [9], [4, 6], [1], [7], [0], [1], [4], [5], [0], [2], [9], [4], [5], [0], [3], [4], [7], [2], [3], [0], [1], [4], [7], [9], [9], [0], [7], [5], [2, 6], [7], [1], [2, 6], [3], [7], [3], [6], [8], [4, 6], [9], [8], [4], [9], [2], [3], [4], [0], [2], [3], [6], [0], [5], [3], [5], [8], [3], [4], [4], [9], [5], [6], [3], [8], [2, 6], [1], [8], [5], [5], [8], [6], [5], [9], [0], [4], [2, 5], [0], [5], [9], [9], [3], [8], [0], [6], [0], [2], [3], [7], [8], [2, 9], [6], [9], [1], [5], [2], [2], [7], [9], [3], [9], [3], [5], [2], [2], [2], [8], [8], [5], [0], [0], [7], [0], [3], [1], [6], [5], [0], [9], [2], [6], [7], [4], [0, 2, 9], [0], [0], [7], [2], [3], [2], [4, 6], [4], [2], [7], [8], [0], [1], [0], [1], [3], [6], [4], [8], [0], [6], [0], [9], [1], [6], [2, 5], [1], [0], [1], [3], [0], [4], [7], [9], [9], [3], [7], [2, 5], [7], [1], [6], [6], [9], [1], [1], [4], [0, 4], [2], [1], [7], [0], [1], [2], [1], [1], [3], [2], [6], [9], [1], [3], [2], [0, 2, 9], [0], [7], [3], [4], [6], [4], [6], [9], [4], [8], [9], [2, 3, 5], [0], [5], [7], [2], [2], [2], [2, 9], [9], [2], [8], [7], [1], [1], [2], [2], [2], [2], [9], [1], [2], [6], [1], [2, 6], [1], [8], [9], [2], [2, 3], [1], [9], [9], [3], [4], [5], [2, 5], [0], [3], [2, 5], [7], [1], [7], [7], [1], [8], [1, 9], [3], [5], [5], [1], [6], [2], [0, 2, 9], [8], [4], [3], [3], [5], [9], [8], [8], [5], [1], [0], [6], [7], [0], [9], [6], [0], [0], [8], [7], [1], [2], [6], [9], [1], [6], [4], [7], [1], [0, 2, 7, 9], [0], [0], [3], [2], [8], [3], [8], [4], [8], [4], [0], [8], [3], [3, 6], [1], [2, 5], [3], [0], [5], [0], [4], [1], [7], [2], [0], [1], [3], [9], [1], [6], [1], [6], [1], [2], [8], [7], [0], [9], [5], [0, 4], [0], [0], [1], [7], [9], [7], [1], [9], [2], [1], [9], [0, 4, 7], [3], [6], [0], [2], [0], [0], [9], [2, 3, 9], [8], [9], [4], [5], [4], [3], [0], [7], [8], [7], [3], [7], [3], [4], [6], [5], [9], [3], [2], [4], [2, 5], [7], [9], [6], [7], [0, 4], [7], [1], [2], [3], [1], [9], [3], [6], [8], [3], [7], [7], [0], [8], [1], [5], [2], [2, 5], [3], [3], [6], [3], [3], [9], [8], [4], [2, 6, 8], [8], [0], [0, 4], [1], [7], [8], [4], [9], [5], [2], [6], [2, 6], [8], [8], [6], [7], [3], [8], [1], [1], [5], [3], [7], [9], [9], [9], [8], [5], [9], [9], [6], [8], [8], [4], [8], [1], [0, 4], [1], [8], [8], [6], [5], [9], [0], [6], [1], [6], [6], [6], [2], [5], [6], [5], [3], [3], [3], [6], [8], [9], [4], [4], [3], [8], [5], [6], [0, 8], [8], [5], [7], [8], [4], [2, 6], [5], [3], [1], [8], [3], [0, 8], [0, 4], [0, 3, 4, 7], [0, 8], [3], [5], [3], [3], [2], [7], [7], [2, 8], [4], [0], [5], [3], [6], [1], [1], [3], [9], [9], [3], [6], [7], [1], [8], [3], [9], [2, 5], [7], [8], [8], [0], [3], [2], [4], [8], [7], [2, 5], [7], [1], [8], [7], [3], [2], [4], [4], [3], [8], [6], [1], [1], [6], [3], [2, 3, 6], [2], [8], [9], [8], [3], [3], [1, 8], [1], [1], [0], [5], [2], [0], [5], [0], [5], [0], [6], [3], [1], [6], [6], [3], [0, 9], [4], [8], [3], [0, 4], [5], [1], [1], [2], [9], [2, 7, 9], [8], [5], [5], [8], [4, 6], [9], [0], [8], [0], [3], [1], [2], [3], [3], [5], [3], [8], [0, 2, 9], [4], [6], [4], [2], [4], [3], [8], [9], [6], [2, 6], [6], [3], [5], [2], [7], [7], [4], [4], [9], [5], [8], [3], [7], [7], [8], [5], [3], [9], [1], [6], [2, 3, 4, 5], [3], [3], [3], [8], [5], [6], [1], [3], [7], [9], [6], [1], [6], [4], [0, 9], [0], [5], [7], [4], [9], [1], [2, 6], [0], [2], [7], [8], [7], [2, 5], [9], [6], [1], [6], [6], [4], [2, 6], [2], [1], [8], [4], [4], [0, 4], [8], [3, 5], [8], [9], [4], [3], [2], [3], [1], [3], [0], [1], [1], [1], [1], [6], [8], [5, 7], [1], [3], [0], [4], [7], [0], [5], [0], [6], [2], [0], [9], [8], [2, 6], [8], [3], [8], [2, 6], [0, 4], [2, 6], [0], [6], [1], [8], [7], [6], [2], [2], [6], [5], [2, 6], [9], [2], [3, 4, 5], [4], [9], [8], [5], [3], [9], [3], [5], [7], [1], [8], [5], [8], [6], [0, 4, 7], [5], [1], [3], [0], [4], [1, 9], [9], [7], [4], [9], [2], [1], [4], [4], [5], [9], [8], [7], [2], [1], [6], [9], [7], [3], [6], [0], [8], [0, 8], [2], [0], [4], [9], [0, 4], [5], [3], [4], [3], [3], [1], [0], [0, 4], [0], [4], [4], [2, 9], [1], [3], [2, 8], [0], [2], [1], [1], [0], [4], [1], [9], [4], [8], [1], [1], [1], [5], [9], [0, 8], [1], [6], [7], [2], [9], [9], [7], [8], [8], [1], [0, 2, 9], [7], [8], [0, 2, 9], [1], [6], [6], [3], [3], [1], [3], [0, 8], [8], [8], [3], [2, 6], [6], [7], [9], [0], [7], [6], [4], [1, 8], [2], [0], [6], [3], [0, 8], [6], [2, 5], [1], [1], [8], [6], [7], [0], [5], [4], [3], [2], [1], [7], [8], [2], [0], [1], [7], [4, 8], [8], [7], [6], [6], [7], [0], [0], [4], [9], [0], [6], [2, 5], [1], [3], [8], [6], [1, 8], [1], [9], [6], [7], [6], [5], [0, 9], [6], [0], [1], [3], [1], [1], [5], [3], [4], [3], [3], [8], [1], [6], [6], [1], [8], [8], [6], [2], [7], [4], [6], [8], [9], [3], [2, 5], [4], [5], [3], [1], [4], [1], [2, 9], [5], [1], [7], [7], [4, 7], [5], [2], [8], [2], [6], [6], [6], [4], [0], [7], [1], [7], [2, 3, 6], [0], [3], [1], [0, 4], [4], [1], [2], [2], [4], [9], [2, 8], [2], [8], [5], [6], [3], [4], [7], [3], [3], [1], [5], [3], [0], [4], [3], [4], [9], [4], [7], [9], [1], [7], [8], [3], [1], [8], [3], [2], [5], [7], [2], [7], [9], [6], [8], [6], [8], [6], [5], [9], [0], [4], [8], [5], [6], [6], [2, 5], [8], [0], [4], [8], [6], [7], [2], [2], [1], [7], [4], [1], [2], [0, 4], [2], [2], [8], [7], [2], [2], [5], [7], [7], [6], [8], [9], [9], [5], [5], [2], [9], [8], [7], [2], [0, 2, 4, 7], [3], [7], [4, 7], [3], [2], [1], [9], [3, 8], [1], [5], [3], [2], [6], [3], [9], [1], [5], [4], [3], [6], [2, 9], [0, 4], [9], [7], [8], [0], [8], [9], [1], [2], [5], [7], [2], [0], [2, 6], [6], [1], [2, 6], [4], [0], [5], [0], [0], [5, 7], [4], [6], [5], [6], [4], [8], [3], [0, 4], [5], [5], [0, 4], [6], [6], [7], [3], [0], [9], [9], [6], [1], [0], [4], [6], [2, 5], [0], [9], [2, 6], [6], [6], [3], [2], [1, 2, 8, 9], [0], [1], [9], [1, 2, 9], [7], [2], [3], [0], [2], [7], [6], [4], [2, 3], [0], [8], [2, 3], [0], [0], [9], [6], [6], [6], [8], [4, 7], [4], [1], [8], [1], [2], [2], [4], [8], [5], [2], [6], [5], [7], [9], [1], [0], [7], [2], [2], [4], [0], [0], [4], [2], [2], [4], [0], [4, 5, 7], [9], [4], [1], [8], [4, 7], [5], [5], [9], [0, 8], [5], [7], [8], [0, 9], [9], [8], [9], [1], [6], [3], [8], [0], [3], [4], [4], [8], [4], [8], [9], [8], [6], [0], [0], [8], [2], [0], [4], [2], [7], [6], [0], [5], [8], [0, 4], [1], [9], [0], [1], [4], [4], [8], [4], [9], [6], [0], [0, 4, 7], [4], [6], [8], [9], [6], [2], [0, 8], [4], [9], [4], [9], [3], [9], [2, 5], [6], [7], [0], [9], [7], [1, 8], [8], [4, 6], [0], [6], [4], [4], [1], [9], [2], [6], [7], [9], [8], [3], [9], [2], [1], [2], [7], [4], [1], [0], [0], [2, 3, 5], [6], [0], [4], [3], [2, 5], [8], [2, 8], [0], [6], [9], [5], [2], [8], [7], [8], [6], [5], [9], [4], [2], [4], [6], [9], [6], [2], [2], [4], [1], [0], [5], [9], [8], [9], [3], [5], [9], [3], [8], [1], [6], [3], [7], [3], [6], [2], [0], [2], [8], [2], [8], [2, 7], [7], [8], [1], [0], [4, 8], [9], [7], [0], [3], [8], [0], [5], [9], [5], [8], [2, 5], [2], [0], [9], [2], [4], [4], [4], [9], [2], [2, 9], [5], [3], [1], [3], [2], [0], [0], [4], [9], [6], [3], [8], [2, 9], [5], [8], [6], [4, 7], [8], [2, 5], [3], [9], [7], [9], [7], [1], [2], [1], [9], [6], [9], [2], [7], [9], [4, 6], [4], [0], [6], [2], [4, 7], [1], [2, 5], [7], [2], [8], [5], [9], [0], [3], [2], [3], [2], [7], [6], [3], [2], [5], [9], [0, 8], [5], [1], [9], [8], [7], [7], [4], [8], [6], [3], [2], [3], [1], [0], [4], [1], [8], [8], [4], [9], [4], [4], [4], [3], [9], [2], [0], [1], [1], [1, 8], [4], [4], [8], [3], [6], [9], [5], [7], [2, 6], [2, 6], [5], [4], [7], [3], [3], [2, 9], [0], [1], [5], [9], [5], [7], [6], [0], [4], [2], [2], [5], [6], [3], [8], [9], [5], [6], [1], [4], [5], [4], [6], [7], [2], [1], [0, 9], [2], [0], [0, 4], [9], [8], [8], [9], [1], [1], [5], [0], [0], [8], [7], [1], [7], [4], [5], [4], [3], [3], [2], [0], [6], [2, 6], [0], [1], [3], [9], [8], [3], [7], [8], [0, 2, 9], [4], [8], [9], [0], [9], [7], [1], [2, 6], [2, 5], [9], [5], [2, 6], [9], [2, 3, 5], [9], [8], [7], [7], [1], [6], [8], [3], [9], [3], [1, 8], [2], [5, 7], [1], [8], [2], [0], [9], [7], [9], [8], [8], [6], [7], [3], [7], [1], [3], [9], [0], [9], [2, 5], [6], [7], [2, 9], [3], [3], [0], [5], [9], [7], [3], [5], [0], [6], [5], [1], [8], [2], [7], [3], [9], [0], [0], [2], [0], [8], [7], [3], [7], [8], [9], [3], [7], [9], [7], [8], [7], [9], [8], [5], [4], [0, 8], [3, 7], [7], [2], [3], [8], [2], [1], [9], [3, 4], [2, 3, 7, 8], [3], [9], [5], [5], [8], [7], [3], [5], [3], [5], [9], [7], [6], [2], [3], [6], [4], [5], [9], [4], [2], [1], [9], [2, 6], [0], [2, 5], [6], [4, 7], [4, 7], [7], [9], [0], [7], [4], [3], [5], [3], [1], [1], [2], [6], [8], [2, 6], [1], [7], [8], [5], [9], [6], [1], [8], [5], [0], [6], [0], [9], [2], [6], [5], [8], [9], [2, 5], [5], [6], [2, 5], [9], [1], [2, 5], [1], [8], [7], [1], [7], [4], [2], [4, 7], [9], [7], [5], [2], [9], [9], [4], [3], [2], [1], [3], [0, 8], [7], [9], [0], [4], [5], [7], [5], [2, 6], [8], [7], [2, 6], [9], [6], [9], [3], [8], [5], [6], [6], [9], [5], [7], [8], [0], [3], [0], [7], [4], [8], [2], [5], [1, 9], [3], [2], [2], [6], [4], [1], [2, 7, 9], [4], [4, 6], [5], [1], [3], [7], [2, 5], [1, 2, 6, 9], [3], [7], [0], [8], [4], [4], [5], [7], [2, 9], [5], [4, 7], [3], [1], [6], [8], [0, 2, 9], [3], [3], [1], [6], [1], [7], [0], [3], [4, 6], [2], [9], [4], [5], [8], [7], [7], [0], [9], [4, 6], [8], [0], [2, 8], [2], [8], [5], [7], [7], [2], [2], [0], [0, 8], [0], [7], [4], [1], [6], [6], [8], [8], [9], [0], [9], [0], [1], [3], [3, 4, 6], [0], [9], [2, 6, 8], [6], [4], [6], [3], [4], [0, 8], [8], [4], [1], [4], [0], [6], [3], [0, 9], [9], [9], [1], [9], [1], [2], [2, 5], [5], [4], [2], [9], [2, 6], [0], [2, 9], [6], [6], [8], [0], [6], [1], [4], [6], [1, 8], [0], [5], [4], [1], [2], [0], [9], [6], [4], [2], [4], [6], [5], [9], [7], [7], [4], [6], [2, 5], [0], [1, 9], [2, 9], [0], [3], [5], [9], [0], [9], [7], [8], [6], [7], [6], [8], [2, 5], [4], [5], [3], [0], [3], [2, 6], [1], [7], [5], [9], [3], [4], [5], [3], [1], [5], [0], [1], [1], [1], [9], [5], [5], [4], [9], [7], [8], [1], [0], [2, 9], [8], [5], [6], [7], [0], [6], [4], [8], [4], [4], [6], [6], [3, 7], [8], [1], [8], [4], [6], [5, 7], [9], [2], [2], [1], [4], [9], [1], [6], [7], [2], [0], [1], [2, 6], [6], [5], [2], [2], [5], [4, 6], [0], [0, 9], [0], [1], [5], [3], [3], [5], [8], [7], [2, 3, 5], [6], [3, 5], [8], [0], [3], [9], [4], [6], [5], [1], [1], [0], [5], [3], [9], [4], [8], [1], [7], [7], [9], [9], [4, 7], [2, 6, 8], [6], [3], [2], [8], [2], [7], [2, 6], [7], [0], [2, 9], [1], [2], [9], [2], [2, 9], [9], [3], [1], [0], [1], [8], [7], [0, 9], [0], [2, 5], [7], [4], [3], [4], [9], [5], [9], [0], [7], [4], [5], [8], [1], [4], [7], [9], [9], [8], [8], [2, 6, 8], [3], [7], [0], [1, 8], [9], [2, 6], [2], [2], [3], [2], [9], [7], [7], [2, 6], [8], [5], [6], [1], [3], [5], [0, 9], [9], [1], [3], [0, 2, 9], [0], [3], [0], [2], [0], [7], [2, 6], [9], [2, 5], [5], [7], [6], [5], [9], [5], [6], [1], [0, 2], [4], [0], [2], [7], [8], [4], [4], [0], [9], [5], [9], [4], [9], [3], [2], [5], [3], [2, 5], [2], [8], [8], [6], [0], [1], [6], [2, 8], [0], [8], [5], [0], [4], [9], [1], [5], [7], [1], [2, 6], [0], [1], [5], [2], [8], [1], [1], [3], [8], [1], [8], [1], [8], [5], [1], [1], [0], [5], [0], [4], [0], [3], [1], [4], [0], [4], [9], [5], [1], [2, 6], [2], [7], [8], [7], [2], [4], [5], [3], [7], [0], [4], [1], [5], [9], [8], [0], [2], [0], [4, 7], [6], [0], [4, 6], [9], [7], [5], [8], [4], [6], [0], [6], [0, 2, 9], [6], [8], [1], [1], [8], [9], [7], [2], [9], [0], [2], [2], [9], [0], [2, 6], [5], [3, 7], [7], [9], [1], [7], [9], [8], [4], [5], [0], [8], [0], [0, 4, 7], [5], [2], [1], [4], [4], [8], [9], [7], [8], [2], [6], [6], [0], [1], [1], [1], [8], [1], [4], [4], [0], [7], [8], [2], [1], [2], [5], [0, 4, 7], [6], [0], [5], [7], [4], [4], [3], [9], [5], [8], [8], [0], [0, 8], [7], [4], [1], [8], [4], [9], [5], [4, 6], [1], [7], [7], [7], [7], [0], [3], [8], [4, 6], [3], [0], [5], [4], [0], [8], [0], [0, 9], [9], [2], [0], [3], [4], [8], [2], [2], [6], [4], [5], [2, 6], [2], [9], [4], [0], [1], [7], [5], [5], [7], [3], [0], [4], [2, 6], [0], [7], [2, 5], [8], [0], [8], [4], [7], [0], [3], [5], [3], [0, 8], [3], [5], [1], [7]]\n",
            "[0.88651857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "BQZ0h_v9P_Vd",
        "outputId": "0f2aa1b3-a008-4654-c365-4d9775fcf0ad"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imshow\n",
        "imshow(x_test[7])\n",
        "print ('lable: ',y_test_label[7])\n",
        "print ('prediction: ',imprecise_results[7])\n",
        "plt.show()\n",
        "imshow(x_test[20])\n",
        "print ('lable: ',y_test_label[20])\n",
        "print ('prediction: ',imprecise_results[20])\n",
        "plt.show()\n",
        "imshow(x_test[25])\n",
        "print ('lable: ',y_test_label[25])\n",
        "print ('prediction: ',imprecise_results[25])\n",
        "plt.show()\n",
        "#label_dict = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer',\n",
        "#              5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lable:  [6]\n",
            "prediction:  [2, 6, 9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "lable:  [7]\n",
            "prediction:  [3, 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "lable:  [2]\n",
            "prediction:  [2, 4, 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARoAAAEYCAYAAACDezmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAf90lEQVR4nO3da4xc53kf8P9zzpyZ2TvJXYpaUbQoyZIcWakpgVHUWAjSJHYVI4BkNDDsD4Y+GFFQxEANpB8EB0hcoB+corZhoIULuhaiFK4viW1YCIw0jhBUcJvIpmRJlk3JupiURPOyJHe517mcc55+2JFLS3z/73LJd3e1+v8Agrvz7Dvznss+OzPnmec1d4eISErZZk9ARLY/JRoRSU6JRkSSU6IRkeSUaEQkOSUaEUmucTmDzeweAJ8HkAP47+7+afbz7XbTx8aGgvFuzS+1D4+Hx+aNnI5F5Cq+RXKuWxUORtJ1rIDAzCI/UUceIDaePvplheuK7Jcy8tA1v/Ms4zvWGnx8VYfnVpV8ny7NdmjcI4dkdGebxvNmeNuqPtmnAJDzM8picXrCRg545GQ+9fLMGXff/cbb151ozCwH8F8BvA/AawB+YGaPuPtPQmPGxoZw37+5O3ifRxdX6GMe+Ne3BWM7JnfQsd7jJ23DWjTeL5aCMRviZ10VOTpFgz926Qs0njsZ73y760iSygt+iiyfPx++7xk6FNbl9z00zPdLc2f4Dw8AnFs6F4wtzi7Tsf/8zedovFrmc7/rvltofNe+8LbNn1nkjz3Gf09ao/x8y60ZjGXsXAJQV/x8+syH/suxi94vHcXdCeBFd3/Z3XsAvgrg3su4PxHZpi4n0ewF8OoF3782uE1E5JckfzPYzB4ws8NmdrjT6aV+OBHZgi4n0RwHsO+C768d3PZL3P2Qux9094Ptdvi1oYhsX5eTaH4A4CYzu97MmgA+DOCRKzMtEdlO1n3Vyd1LM/s4gP+F1cvbD7n7j6/YzERk27isOhp3/w6A76z55xuGcmcRjL/n166h44fGwtMt0adjmxP8ZVsf/HKnI1zb0Cx4zYQ5f2+qqrs0XhSRl5zkamaswqYs+XbX3Ugty0L4cmg7Dx9rAGhfy7erNF6I04vs19ZweOsXTvKShO4cr2UZ2zFJ47PH+CXomePha/9TNwzTsZNju2i8Mv67YAjXnFkkJVTZ+mq2VBksIskp0YhIcko0IpKcEo2IJKdEIyLJKdGISHJKNCKS3GXV0VyqYriJ6Tv2BeP5KJ9O3g7XPjQiKbNf87qGPHIH7KP18QVreD2IRe4hA6/T6ZXhOpxuFakPitTwNOtxGmetHKzBt6tn/Jj0O3xuHukpkxfhmo/507wVQ7fLa3QmIj2CXnthjsYL0o3hutt20rHtIV5/1OtH+vSQ1iEeabSTq45GRLYqJRoRSU6JRkSSU6IRkeSUaEQkOSUaEUluQy9v50WO8atHgvFOny9xUZNWDRX4pdLKIxehnbc0qEkbCvaxewBoNvjH/rMs8tH8SDsEtl/qPr9cOWyRS6kYpfE8C297B/wScsP5fnPwY9Kv+PmSN8L7tb/CWymUvcildbKUCwDUNf8bXpC5rZzn5RBDV/NzuRtp/bG6gEkoFmkLUvNVEkL0jEZEklOiEZHklGhEJDklGhFJTolGRJJTohGR5JRoRCS5Da2jca/Rq8O1Dw322XkAdUVqFypee4DIx/rrmteq5I1wTUdBYgBgsU/WR2p8LHIHzWa4jcRwxts8lEu8FiXWisFJLUy/z/dp1ojUH0VWNm1kfL9npCakF1ueOXJMYq1Bqj4/H/vkb/yp55fo2HqUP3p7J6/xGW5PBGO92O/BOp+b6BmNiCSnRCMiySnRiEhySjQikpwSjYgkp0QjIskp0YhIcpdVR2NmRwEsAKgAlO5+kP28o0ZJepSMWPj6PgBYFq4fYPU5ANAqIku5FLymg/WEKfIhOraueS1KFelt0irCPXwAYKUX7j9SG3/sssX7+PSMz61pZLmVitfBeC+2zyMFSDmvVSla4eNSVrwWJc8jfVkitU1e8/uvER6/dIbv88kFPreR6TEad9IrJ3IqYmdzD/+BgCtRsPev3P3MFbgfEdmm9NJJRJK73ETjAP7ezJ4wsweuxIREZPu53JdOd7v7cTO7CsB3zew5d3/swh8YJKAHAGBiD3+vQUS2p8t6RuPuxwf/nwbwLQB3XuRnDrn7QXc/ODzB3zQVke1p3YnGzEbMbOz1rwG8H8CzV2piIrJ9XM5Lpz0AvjW4zNcA8D/d/e+uyKxEZFtZd6Jx95cBvOdSxmRWYMiuCceryDo+vhCM5RYZ2+Pr+PTA18JpNcLrG7G6BACo60ivHIv0LqnC2w0AFVnXqVHwl6ujzatpfCXjvVE6Zbi+qNXcQceWPk/jec3H90o+t6Id7tPTJDEAcIv0oyFrIwFAHqnbqjxc39Tr8HP11I/5ud6OvEUxdfVUMOa9c3zs+K00HqLL2yKSnBKNiCSnRCMiySnRiEhySjQikpwSjYgkt6HLrRgMLdJWoIws9eAWjvf7/PPtHmmX0Izk3CIPtzwoe7xFRRVZ6mV0dJjG+yv88vdQSZapGeL7dH5llsfP80vIw0Ph1h5Vzu87G+WXiIcL3ophpNpJ4xVpxZDnkcvTZBkZAECkDYTl/FerLMPHtN/jx3v+JH/sziw/30ZuDl/+XurzsdNTe2k8RM9oRCQ5JRoRSU6JRkSSU6IRkeSUaEQkOSUaEUlOiUZEktvQOhpHjTILt2PIIrUNvcVw/cDi8gwdOzbBl6BoFbtpvNsP18p0+13+2EOTNN7s8I/1L//v4zR+zUJ421bewZdT6byb12zsnrqKxsuSbHvF2x0M57wOxsBbv1aR5VZ6VfiY5S3eaiFvRJZLiSxD4xb51fLw/ZcV365YC4tGn29btzoZjO29mv8eTO7aT+MhekYjIskp0YhIcko0IpKcEo2IJKdEIyLJKdGISHJKNCKS3IbW0axW0pDaCl4egAbp8TE+xGsyspz32ejWizTuVXj8ruFr6dgS/L5XfsqXuBh+8hUaH2mMB2N7Rnj/kKUer+HJd4XvGwBKsjxHpGULFrunabxV8loVkCVLAICVsuQFr/GxyOQ9Es+bvJeOWzjOYgBgNa83e+0IrymbvuW6YOyd73rTYrO/5OxMuC8To2c0IpKcEo2IJKdEIyLJKdGISHJKNCKSnBKNiCSnRCMiyUXraMzsIQC/D+C0u982uG0XgK8B2A/gKIAPuTtfxAcA3IAynNvKSF1E3Qn36Rhu8XqPKlJ70FsO98kBgKEivH5Ro+brMq1UkV1zitfZtDu8nuR8EV67qVWP0rGNjK9JVRvfL0Z2a02ONQAUIOtRAbBIP5ui0abx2sP7bWIn3y/NFj9fnKzLBABZi2+7kaIxJ+tRAfF+Nd0lHr9p+tfD9714PR377CtzNB6ylmc0fwngnjfc9iCAR939JgCPDr4XEbmoaKJx98cAvLH8814ADw++fhjAfVd4XiKyjaz3PZo97n5i8PVJAHuu0HxEZBu67DeD3d1BPqVkZg+Y2WEzO7x0nr/eF5Htab2J5pSZTQPA4P/gp+Pc/ZC7H3T3gyMT/E1TEdme1ptoHgFw/+Dr+wF8+8pMR0S2o2iiMbOvAPgnALeY2Wtm9jEAnwbwPjN7AcDvDr4XEbmoaB2Nu38kEPqdS30wB1BX4Yfsk3V4AKCZh3untJ3X0Sz1+NpL6PO6ieUyvD5Sr+L9YtotXu9xZmaBxm/o878HVRGe+9Pn+H3bIj8FiqElGs8Qfuwi49uNBj8mRaSHUCOL9BjqhetJdu7ma22N7OIv83vLkV45GT9mNY3z7eqT7QKAsR28FmZy8uZg7PF/PkvH9oodNB6iymARSU6JRkSSU6IRkeSUaEQkOSUaEUlOiUZEktvQ5Vbca3Sr+WC83wu3OwCAPA9fWps9f56OLcEvpeak1QIAVHX4kmI2xPN1xtb9AHC6z9shTPX53KZJWcDc+eN07GjnGhofKXgrhyIrgrGVXrgkAAB6fR7PmvwScg0eL4pwyUPe5peILbLkSd7g5RDYOUbDVSd8zKzP58bORQDYd/ONNH7qTPh8fPInp+jYA782ReMhekYjIskp0YhIcko0IpKcEo2IJKdEIyLJKdGISHJKNCKS3IbW0ZgBjWa4PsFqPp2sCI8d2sVbEmRZk8ZL8FqVLCdzy/lYz3m9x3zJx5/t8/HDC+FWEDPDvE3Ezh38Y/9WhFtzAEBNOhrkGT+eEy1ek9GteYuKipe60DYTpfO2snWH1101ixEan6v4Ma1Xwvefl7yuaniU1+jsv+lXaPzZI+FatlOneT1aHqkJC9EzGhFJTolGRJJTohGR5JRoRCQ5JRoRSU6JRkSSU6IRkeQ2tI6mqivML4av4RfgtS5m4dqEdovXmnRrXtdQFHx5jaIZrslYXRU4rK5575I60o/mxeVZGj9ahWsyfrrAi03GX7uKxveN8fqk7spMMGaR2qWhnN93XfO/gx3nNR/GWulU/HzJ+/yY9ru8Dme5f5LGh0j9Ua/Lz9V33x5eLgUArDlN408+/Xww5iVf8ghkeR1Gz2hEJDklGhFJTolGRJJTohGR5JRoRCQ5JRoRSU6JRkSSi9bRmNlDAH4fwGl3v21w26cA/CGA14soPunu34ndV4Ycw9lEMD4yspOOz3vhNYR6C5H+H6QOBgBK471PetVcMNZsjtKxrJUNAHQj6zbVkX41nSpchzMzy9cAOvp/+HbvvYnXwrRJnU2/w2tVTs6E6zkAYGJiD43HTt/Z+XD9UVnyPjve5D1ful2+X9vLvA9Qayy8bX3wtbSW+7wXzg+eOEbjx154MRhrVrw+KHd+TEPW8ozmLwHcc5HbP+fuBwb/oklGRN6+oonG3R8DcG4D5iIi29TlvEfzcTN7xsweMjP+mkdE3tbWm2i+AOBGAAcAnADwmdAPmtkDZnbYzA4vz/O1lkVke1pXonH3U+5euXsN4IsA7iQ/e8jdD7r7weFx/gaciGxP60o0Znbhx0M/CODZKzMdEdmO1nJ5+ysAfgvAlJm9BuDPAfyWmR0A4ACOAvijtTxYlhnazfBD5s7znpFlTcqCX5azgrdiKAv+sm6k2B2MFbQfAdCrIi8Z+/wwnF3mH91nFxxbw/xS6Kmf8lYLJ57/OY1P3Rre9smh/XRs+yr+1t5yeZbGLbYMDdmt/Zofs6LNSxZ2TPDL/iMNvt+PzoXLJcaLcBkHAMzM8fYaz7xymMarbvh8arb5djXyyBo3oXGxH3D3j1zk5i+t69FE5G1JlcEikpwSjYgkp0QjIskp0YhIcko0IpKcEo2IJLehy63UXmOlDC8N0u/xepOafITdcv6x/dFmuA4GACrnVcsr/fDH/vsZX5qjAK/J6Czy7T67ElkCoxWuq2hF5mbz4eVvAODo/+W1LMNXhdsdtMf4drUy3oqhJLUmAGDgNR3dufC2n338BB17VWS5lTrnNTzjk5E2E2dOBWOdkt/3u6f5r+0iwq1YAGDuXHiJnEaDt1PJItsdHLeuUSIil0CJRkSSU6IRkeSUaEQkOSUaEUlOiUZEklOiEZHkNrSOxszQKMIP2Y70uihsMhwkvWpW8U3tR5bPKJvh+p+lxUU6tsiGabwXWU6lNP73wMn4nLfhwUib75fzx3hdxcrz4RqeiV+J1Cad4L1wll/iNTzo8t4pCy+Hl1tZfIX32SmqyDGpeD3J8ZfCS5oAwOxC+JwZ3nMdHXtdwed+coKPf/p8+Lg0Ml77lOfre26iZzQikpwSjYgkp0QjIskp0YhIcko0IpKcEo2IJKdEIyLJbWgdjcPhFu6tUnpOxzeycN1EI+M1G0vLvNalXy3R+FAR7i/S5mUyWFmKrDlV8RqemrdGQUVqOmpeBgOP/a2p+Cly8qlwvcn4ab7Ps4pPzmf4+kXLpBYFAIaWwjUhTeN1MD+P1MnknXB/IgDwDh/fJwd1rOD9h4bBewhd3X+Oxg/PhuvVindcS8c2C75eVYie0YhIcko0IpKcEo2IJKdEIyLJKdGISHJKNCKSnBKNiCQXraMxs30A/grAHgAO4JC7f97MdgH4GoD9AI4C+JC7hxuAAPDa0e2Ea0YaLT6dKgvXXdQrvPGKR1Jqs13QeMPDNR19D/eqAYB+ZJ0ej6xPlDf43EpSj5JF/pb0ar7PG5EanqXlcB3N4ed4T5Y9Y3z9ockm7zezEunTM0MOenPHFB17dpmfT4tVi8bLzhka7yJ8zmRNfryXOrxXTrs6R+O76nB90ejoPjrWMl7rFrKWZzQlgD9x91sB3AXgj83sVgAPAnjU3W8C8OjgexGRN4kmGnc/4e5PDr5eAHAEwF4A9wJ4ePBjDwO4L9UkReSt7ZLeozGz/QBuB/A4gD3u/vq6oiex+tLqYmMeMLPDZnZ4eT6ytKuIbEtrTjRmNgrgGwA+4e6/9GELd3esvn/zJu5+yN0PuvvB4XH+2RUR2Z7WlGjMrMBqkvmyu39zcPMpM5sexKcBnE4zRRF5q4smGjMzAF8CcMTdP3tB6BEA9w++vh/At6/89ERkO1hLm4j3AvgogB+Z2VOD2z4J4NMAvm5mHwNwDMCHYndkaKCF8GXFsssvnVVkWZFWNk7Hdvp8aY88460cmlm4TYRhlI6ta36p1DL+ktIyfvk7q8PxPOPXp3uxNhJ9ful+cT68JIpFWjHMl/w9u4UuX/pjcYW39sjI5fPRId7uoJ4/TuMrTd6WpDd2A433514Nxqoe3+cn5vh2zy7N0fj0DeH9fv2Bi77V+gtVvb7Su2iicffvAcFCj99Z16OKyNuKKoNFJDklGhFJTolGRJJTohGR5JRoRCQ5JRoRSW6Dl1up0C3Dy1Q0W7yepE/qLroV/+h8Fkmpy4u81mWlCteLDMfWW+nz+qDlBb50RxmpZclIrYxH6mTKi39y5BeK6HIs4RqelQ6vTVqc5/UevV6kTqbg7RRuuXZ/MNaveY3PmSX+2GVkeZ/GMG+BUdreYGzFec3XjM3wx343b2Fx443hJVV2TPD6ol6f77cQPaMRkeSUaEQkOSUaEUlOiUZEklOiEZHklGhEJDklGhFJbmPraOoaXVIb0SvngzEAyLNw35dWg/ds6XZ5nY1HlpFY6oRrG6oystTLMq+zqbrhJWgAAMaLYbI8XE9SN3i9h+W8dinP+JInjTy8bUtLJ4IxAFg4x+NlxWs2xnbxJVOKVnjbZ8+E66IAYKni+6WKHDJffInHs/B+W77mKjp28u5wDQ4AtKciy/s0wud6ucJ/D3pNfq6H6BmNiCSnRCMiySnRiEhySjQikpwSjYgkp0QjIskp0YhIchtaR5NlDYy2dwXjiwu8B8hCZzYYmy9P0bH9Dq9Fmb5mH413qnD9QNd5TcbCzBkab+e8f8jQEK+F6ZfhGqL2EF9zKm/wvzWLy3zup8+Ej1l3OXy8AGCxs0jjec5Pz+mreL3J8ROvhGOnztGx8V8N3sdneZGfE5mFt31p+Ro6tt/jvW72TfH9cu4smVvF66bKnupoRGSLUqIRkeSUaEQkOSUaEUlOiUZEklOiEZHklGhEJLloHY2Z7QPwVwD2YLV44JC7f97MPgXgDwG8vsjMJ939O+y+HBW6Fu4502zy6aycC69vVHd4H41dU7x3SY3wmlEAUJC7b4/w+y7Ba3j6fV4DNDQ8TuO+GK7JcON1D92Kz232HF9DqNsNP3bd5ft0JdIjaHonX2PoD37jdhp//mfHgrGfvfgCHXt+me+3nPThAQA47wlT1uF9c/Yo72Uzc5Tvl+HdfF2ofi/ca2e0weuuqpqvMRayloK9EsCfuPuTZjYG4Akz++4g9jl3/8/remQReduIJhp3PwHgxODrBTM7AoC3+BIRucAlvUdjZvsB3A7g8cFNHzezZ8zsITPbGRjzgJkdNrPDy+f5U2kR2Z7WnGjMbBTANwB8wt3nAXwBwI0ADmD1Gc9nLjbO3Q+5+0F3Pzg8wfuwisj2tKZEY2YFVpPMl939mwDg7qfcvXL3GsAXAdyZbpoi8lYWTTRmZgC+BOCIu3/2gtunL/ixDwJ49spPT0S2g7VcdXovgI8C+JGZPTW47ZMAPmJmB7B6yfsogD+K3VFZVpg7G768PTrMP/7eaoUvKQ7t4JeA8wl+GXdhhbdDyLNwq4bJ8Vvo2FmE2xUAwNw8b6eQ85Vk4CSeZ3zwSmeFxqs6spRMHb6MW5EYACCyxM35Hr/8/f2nnqTx37j5xmCsvOOddOyRV0/S+GKP/40+37maxvOJcDuGqWne5mF0D99vo8OTNF63xoKx/iJ/eyOLLP0TsparTt8DcLGzldbMiIi8TpXBIpKcEo2IJKdEIyLJKdGISHJKNCKSnBKNiCS3ocutoAbKlfB1+JNLP6fDx1vhOhvPeT1Iu7+DxhvOaxfQC++qc6fn+NCaf2wfGf/o/fzcMo3neRGMNQu+lEtd8lqXfp/Prd8ndTYZX5IkjxQIddh9A/i7H/Ia0fOzJ4Kxu267mY799VvfS+O9OrzPAWCOLIEDAMfy8H5dGeX7bccNvJXDXDdcqwYA1g/Xo7WcL7fSaESKugL0jEZEklOiEZHklGhEJDklGhFJTolGRJJTohGR5JRoRCS5Da2jsSzHUDNcC7NyvqTjF6twz+Gsy+s9psYu2tL4F0ZG+ZIp55fC/WqWFsJLjgDA1J530PjkPr70x8K5BRpnPWPmF3hNhhk/BcpIHY3TpWT4Y3vGe5vE/goudXgP6h++Gl7G5h3X8p4tbrwXzvgwr8vaN7WHxnd1w/v9vPMt393k5+rpU7y3UsfDj90v+HY3c35MQ/SMRkSSU6IRkeSUaEQkOSUaEUlOiUZEklOiEZHklGhEJLkN7kfjqDvh2omdQ7vp8KwIr2dTOa9lKdq8t0mbt/hArw73dSkavIdHu8VrNq69fZrGT7wYrgcBgPlZ1n+E/y3JIz1j6orXNmV5+P6LZrjvCQBUzu+7H6mTqSp+TPdetS8Ym969l44te7zH0MmzvHfS7CLvCXPrZHjdp5v3hOcNAPYar6t651neK6ffCPdHWmn9Ex27vONdNB6iZzQikpwSjYgkp0QjIskp0YhIcko0IpKcEo2IJBe9vG1mbQCPAWgNfv5v3P3Pzex6AF8FMAngCQAfdXf+GXMDrAgv75HxlT/QyMKXmEcaY3xsk1/G7Xd4O4TKw8u5LC3zS6H1OR6//rbraPznz/KP/c9/70gwVpb8ErKTy9MAkDf4KVJ7+KDVdaSlgPOlO3LeRQK/euN+Gr/vvXcFY5Nj4VIJADg+M0vjc0t8CZ1Why//81Id3m8/O8fLGYYKfkx2tYZofOd4ePzYyFk6dnzxORoPWcszmi6A33b39wA4AOAeM7sLwF8A+Jy7vxPALICPrWsGIrLtRRONr3q9Gq4Y/HMAvw3gbwa3PwzgviQzFJG3vDW9R2NmuZk9BeA0gO8CeAnAnPsvSjtfA8BLLUXkbWtNicbdK3c/AOBaAHcCWHMdspk9YGaHzezwygIvKReR7emSrjq5+xyAfwTwLwHssP/fcPZaAMcDYw65+0F3Pzg01r6syYrIW1M00ZjZbjPbMfh6CMD7ABzBasL5g8GP3Q/g26kmKSJvbWv59PY0gIfNLMdqYvq6u/+tmf0EwFfN7D8C+CGALyWcp4i8hUUTjbs/A+D2i9z+Mlbfr1mzqipxbi58nf66qevp+GI5XBPSiDw5O3uG1z0srJymcRsK7ypr85qMMV7WgOExfhh+9f030vgKaacwc2yGj53n9R6jw7wFxpCFt72ueZ3M+BCvfXrXvptp/ODN+2l850j4nHjxZ8/TscfOvErjZaTmq6z5+fjcXPh8bGZ8v7WNx8cidTS7xsNLD03vuYaOHZm56DskUaoMFpHklGhEJDklGhFJTolGRJJTohGR5JRoRCQ5JRoRSc7cIz1DruSDmc0AOHbBTVMAeLOVzaO5XbqtOi9Ac1uvS53bde7+pnWTNjTRvOnBzQ67+8FNmwChuV26rTovQHNbrys1N710EpHklGhEJLnNTjSHNvnxGc3t0m3VeQGa23pdkblt6ns0IvL2sNnPaETkbWBTEo2Z3WNmz5vZi2b24GbMIcTMjprZj8zsKTM7vMlzecjMTpvZsxfctsvMvmtmLwz+D3/mf+Pn9ikzOz7Yd0+Z2Qc2aW77zOwfzewnZvZjM/t3g9s3fd+RuW36vjOztpl938yeHsztPwxuv97MHh/8vn7NzHjvkItx9w39ByDHanPzGwA0ATwN4NaNngeZ31EAU5s9j8FcfhPAHQCeveC2/wTgwcHXDwL4iy00t08B+PdbYL9NA7hj8PUYgJ8CuHUr7Dsyt03fdwAMwOjg6wLA4wDuAvB1AB8e3P7fAPzbS73vzXhGcyeAF939ZV9dcO6rAO7dhHlsee7+GIBzb7j5XqwubwNs4jI3gbltCe5+wt2fHHy9gNXWs3uxBfYdmdum81VJllbajESzF8CF7cu22lItDuDvzewJM3tgsydzEXvc/cTg65MA9mzmZC7i42b2zOCl1aa8rLuQme3HaofIx7HF9t0b5gZsgX2XamklvRn8Zne7+x0Afg/AH5vZb272hEJ89bnsVrps+AUAN2J1RdMTAD6zmZMxs1EA3wDwCXefvzC22fvuInPbEvvOL2NpJWYzEs1xAPsu+D64VMtmcPfjg/9PA/gWLrEv8gY4ZWbTADD4nzc73kDufmpwotYAvohN3HdmVmD1F/nL7v7Nwc1bYt9dbG5bad8N5nPJSysxm5FofgDgpsE72U0AHwbwyCbM403MbMTMxl7/GsD7ATzLR224R7C6vA2wxZa5ef2XeOCD2KR9Z2aG1VU5jrj7Zy8Ibfq+C81tK+y7pEsrbdK72x/A6rvtLwH40818p/0N87oBq1fBngbw482eG4CvYPVpdB+rr40/BmASwKMAXgDwDwB2baG5/Q8APwLwDFZ/qac3aW53Y/Vl0TMAnhr8+8BW2Hdkbpu+7wD8C6wunfQMVhPdnw1uvwHA9wG8COCvAbQu9b5VGSwiyenNYBFJTolGRJJTohGR5JRoRCQ5JRoRSU6JRkSSU6IRkeSUaEQkuf8H1pUaiOaCyFMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}